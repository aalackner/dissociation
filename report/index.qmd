---
title: "FOMA Organic Charge Desnity"
author: "Anna Lackner"
date: today
format:
  html:
    embed-resources: false
    toc: true
    toc-depth: 3
    smooth-scroll: true
    code-fold: true
    theme: lux
    number-sections: true
  docx: 
    toc: true
    toc-depth: 3
    number-sections: true
css: style.css
execute: 
  echo: false
  warning: false
  cache: true
  freeze: true
  keep-md: true
---

# Overview
Based on 35 years of monitoring data of the water chemistry lab at the SLU Department of Aquatic Sciences and Assessment, the charge density of organic matter was calculated for over 40 000 samples across Sweden from water courses. 

# Background

```{r}
#| include: false
# re.read <- 're read' # this lets the script re run the GAM functions
# re.read <- 're load' # here the script reads in the already run GAM data 
re.read <- 're fig' # loads just the figures associated with the data but not the GAM data itself.

library(tidyverse)  
```

In [Eklöf et al, 2020](https://www.sciencedirect.com/science/article/pii/S0043135421007405?via%3Dihub) trends in TOC and SVISa were found to cease  increasing around 2000-2010 widespread across the country.  

---

```{r}
library(tidyverse)

source("../src/sourcecode_screening2024.R")

coordinates <- read.csv("../input/catchment_characteristics/catch_landuse(NMD).csv") %>% select(mvm_id, stationName, stationCoordinateX, stationCoordinateY) %>% rename(x = stationCoordinateX, y = stationCoordinateY)

df <- read.csv("../input/chemistry/chemistry_complete_no_selection.csv")

df %>% left_join(coordinates) %>% mutate(sampling_date = as.Date(sampling_date)) %>%  mutate(TOC =TOC_mol*12.01*1000,sVISa = Abs_F420_5cm / TOC ) -> df
```

### sVISa

```{r}
#| include: false
#Trend plot for sVISa

if (re.read == 're read'){
df %>%  filter(!is.na(sVISa)) %>% # create sVISa and filter any variables where it does not exist
  group_by(mvm_id) %>%  # group by mvm_id to remove andy station where we don't have enough data points
  filter(n() >= 50) %>%  
  ungroup() %>%
     select(mvm_id, sVISa, sampling_date,x, stationName) %>% mutate(SiteID = as.factor(mvm_id))%>% pivot_longer(cols=c("sVISa")) %>% 
    screeningmodeling(values=value,
                    datevar = sampling_date, 
                    link = "identity", 
                    conf.type = "conf",
                    conf.level=0.95,
                    beep = FALSE, 
                    tdist = FALSE,
                    autocor = TRUE,
                    mvm_id,
                    x,
                    stationName, name) ->
  trendplotdata_chemistry_sVISa
  trendplotdata_chemistry_sVISa %>% left_join(coordinates) %>% saveRDS(., file = "data/trendplotdata_chemistry_sVISa.rds")
  }  else if (re.read == 're load') {
    trendplotdata_chemistry_sVISa <- readRDS( file = "data/trendplotdata_chemistry_sVISa.rds")
  }
```

```{r}
#| include: false
#Trend plot for sVISa

if (re.read == 're load'){
  fig <- trendplotdata_chemistry_sVISa %>%plot_proportions()+ ggtitle("sVISa") + 
        theme(text=element_text(size=5), #change font size of all text
        axis.text=element_text(size=5), #change font size of axis text
        axis.title=element_text(size=6), #change font size of axis titles
        plot.title=element_text(size=6.5), #change font size of plot title
        legend.text=element_text(size=6), #change font size of legend text
        legend.title=element_text(size=5)) 
  fig %>% ggsave(file = "figures/sVISa_proportion.png", width = 10,
  height = 6,
  units = "cm",
  dpi = 300) 
}  
```

```{r}
#| include: false
#Trend plot for sVISa

if (re.read == 're load' & exists("trendplotdata_chemistry_sVISa")){
  fig <- trendplotdata_chemistry_sVISa%>% left_join(coordinates) %>%plot_screeningtrends(y_id = mvm_id, sorting = -y) + ggtitle("sVISa")+ xlab(NULL) + 
        theme(text=element_text(size=5), #change font size of all text
        axis.text=element_text(size=3), #change font size of axis text
        axis.title=element_text(size=6), #change font size of axis titles
        plot.title=element_text(size=6.5), #change font size of plot title
        legend.text=element_text(size=3), #change font size of legend text
        legend.title=element_text(size=3.5),
        legend.key.size = unit(0.3, 'cm'))
  fig %>% ggsave(plot = ., file = "figures/sVISa_lasange.png", width = 5,
  height = 20,
  units = "cm",
  dpi = 300)
} 
```


```{r}
#| echo: false
all <- read.csv("../results/r_py/pls_input.csv")
mvm_ids <- unique(all$mvm_id)
df %>% filter(mvm_id %in% mvm_ids) -> df_selected
```

```{r}
#| include: false
if (re.read == 're read'){
df_selected %>%  filter(!is.na(sVISa)) %>% # create sVISa and filter any variables where it does not exist
  group_by(mvm_id) %>%  # group by mvm_id to remocve andy station where we don't have enough data points
  filter(n() >= 50) %>%  
  ungroup() %>%
     select(mvm_id, sVISa, sampling_date,x, stationName) %>% mutate(SiteID = as.factor(mvm_id))%>% pivot_longer(cols=c("sVISa")) %>% 
    screeningmodeling(values=value,
                    datevar = sampling_date, 
                    link = "identity", 
                    conf.type = "conf",
                    conf.level=0.95,
                    beep = FALSE, 
                    tdist = FALSE,
                    autocor = TRUE,
                    mvm_id,
                    x,
                    stationName, name) ->
  trendplotdata_selected_sVISa
  trendplotdata_selected_sVISa %>% left_join(coordinates) %>% saveRDS(., file = "data/trendplotdata_selected_sVISa.rds")
}  else if (re.read == 're load') {
  trendplotdata_selected_sVISa <- tryCatch({
    readRDS(file = "data/trendplotdata_selected_sVISa.rds")
  }, error = function(e) {
    message("An error occurred while reading the RDS file: ", e$message)
    NULL # Return NULL or an alternative value to handle the error gracefully
  })
}
```

```{r}
#| include: false
# Trend plot for sVISa

if (re.read != 're fig' & exists("trendplotdata_selected_sVISa")){
  fig <- trendplotdata_selected_sVISa %>%plot_proportions()+ ggtitle("sVISa") + 
        theme(text=element_text(size=5), #change font size of all text
        axis.text=element_text(size=5), #change font size of axis text
        axis.title=element_text(size=6), #change font size of axis titles
        plot.title=element_text(size=6.5), #change font size of plot title
        legend.text=element_text(size=6), #change font size of legend text
        legend.title=element_text(size=5)) 
  fig %>% ggsave(file = "figures/sVISa_proportion_selected.png", width = 10,
  height = 6,
  units = "cm",
  dpi = 300) 
}  
```

```{r}
#| include: false
if (re.read != 're fig' & exists("trendplotdata_selected_sVISa")){
  fig <- trendplotdata_selected_sVISa%>%plot_screeningtrends(y_id = mvm_id, sorting = -y) + ggtitle("sVISa")+ xlab(NULL) + 
        theme(text=element_text(size=5), #change font size of all text
        axis.text=element_text(size=3), #change font size of axis text
        axis.title=element_text(size=6), #change font size of axis titles
        plot.title=element_text(size=6.5), #change font size of plot title
        legend.text=element_text(size=3), #change font size of legend text
        legend.title=element_text(size=3.5),
        legend.key.size = unit(0.3, 'cm')) #change legend key size))
  fig %>% ggsave(plot = ., file = "figures/sVISa_lasange_selected.png", width = 5,
  height = 20,
  units = "cm",
  dpi = 300)
} 
```

```{r}
#| include: false
# Trend plot for sVISa

if (re.read != 're fig' & exists("trendplotdata_selected_sVISa")){
  fig <- trendplotdata_selected_sVISa %>%plot_proportions()+ ggtitle("sVISa") + 
        theme(text=element_text(size=5), #change font size of all text
        axis.text=element_text(size=5), #change font size of axis text
        axis.title=element_text(size=6), #change font size of axis titles
        plot.title=element_text(size=6.5), #change font size of plot title
        legend.text=element_text(size=6), #change font size of legend text
        legend.title=element_text(size=5)) 
  fig %>% ggsave(file = "figures/sVISa_proportion_selected.png", width = 10,
  height = 6,
  units = "cm",
  dpi = 300) 
}  
```

```{r}
#| echo: false
#| fig-cap: "Proportion plot of sVISa trends across Sweden. Updated from Eklöf et al, 2020."
#| fig-alt: sVISa proportion of trends plot.
#| fig-subcap:
#|      - For all 316 stations that fit the initial selection criteria.
#|      - For the 136 stations charge density was modelled in this study.
#| label: fig-sVISa-prop
#| layout-ncol: 2

knitr::include_graphics(path = c("figures/sVISa_proportion.png","figures/sVISa_proportion_selected.png" ), error = FALSE)
```

```{r}
#| echo: false
#| fig.show: hold
#| fig.align: center
#| fig-cap: "Lasange plot of sVISa trends across Sweden sorted North to South. Updated from Eklöf et al, 2020."
#| fig-subcap:
#|    - All 316 stations that match the initial selection criteria.
#|    - 136 stations for which we could model charge density sucessfully for.
#| fig-alt: sVISa lasange plot of trends plot.
#| label: fig-sVISa-lasange
#| layout-ncol: 2
#| fig-height: 8
knitr::include_graphics(path = c("figures/sVISa_lasange.png","figures/sVISa_lasange_selected.png" ), error = FALSE)
```


### TOC

```{r}
#| include: false
if (re.read == 're read'){
df  %>% filter(!is.na(TOC) )%>% # create TOC and filter any variables where it does not exist
  group_by(mvm_id) %>%  # group by mvm_id to remocve andy station where we don't have enough data points
  filter(n() >= 50) %>%  
  ungroup() %>%
     select(mvm_id, TOC, sampling_date,y, stationName) %>% mutate(SiteID = as.factor(mvm_id))%>% pivot_longer(cols=c("TOC")) %>% 
    screeningmodeling(values=value,
                    datevar = sampling_date, 
                    link = "identity", 
                    conf.type = "conf",
                    conf.level=0.95,
                    beep = FALSE, 
                    tdist = FALSE,
                    autocor = TRUE,
                    mvm_id,
                    y,
                    stationName) ->
  trendplotdata_chemistry_TOC
  trendplotdata_chemistry_TOC %>% left_join(coordinates) %>% saveRDS(., file = "data/trendplotdata_chemistry_TOC.rds")
  }  else if (re.read == 're load') {
  trendplotdata_chemistry_TOC <- tryCatch({
    readRDS(file = "data/trendplotdata_chemistry_TOC.rds")
  }, error = function(e) {
    message("An error occurred while reading the RDS file: ", e$message)
    NULL # Return NULL or an alternative value to handle the error gracefully
  })
}
```

```{r}
#| include: false
#Trend plot for TOC

if (re.read != 're fig' & exists("trendplotdata_chemistry_TOC")){
  fig <- trendplotdata_chemistry_TOC %>% plot_proportions()+ ggtitle("TOC") + 
        theme(text=element_text(size=5), #change font size of all text
        axis.text=element_text(size=5), #change font size of axis text
        axis.title=element_text(size=6), #change font size of axis titles
        plot.title=element_text(size=6.5), #change font size of plot title
        legend.text=element_text(size=6), #change font size of legend text
        legend.title=element_text(size=5)) 
  fig %>% ggsave(file = "figures/TOC_proportion.png", width = 10,
  height = 6,
  units = "cm",
  dpi = 300) 
}  
```

```{r}
#| include: false
#Trend plot for TOC

if (re.read != 're fig'& exists("trendplotdata_chemistry_TOC")){
  fig <- trendplotdata_chemistry_TOC %>% plot_screeningtrends(y_id = mvm_id, sorting = -y) + ggtitle("TOC")+ xlab(NULL) + 
        theme(text=element_text(size=5), #change font size of all text
        axis.text=element_text(size=3), #change font size of axis text
        axis.title=element_text(size=6), #change font size of axis titles
        plot.title=element_text(size=6.5), #change font size of plot title
        legend.text=element_text(size=3), #change font size of legend text
        legend.title=element_text(size=3.5),
        legend.key.size = unit(0.3, 'cm'))
  fig %>% ggsave(plot = ., file = "figures/TOC_lasange.png", width = 5,
  height = 20,
  units = "cm",
  dpi = 300)
} 
```

```{r}
#| include: false
if (re.read == 're read'){
df_selected  %>% filter(!is.na(TOC) )%>% # create TOC and filter any variables where it does not exist
  group_by(mvm_id) %>%  # group by mvm_id to remocve andy station where we don't have enough data points
  filter(n() >= 50) %>%  
  ungroup() %>%
     select(mvm_id, TOC, sampling_date,x, stationName) %>% mutate(SiteID = as.factor(mvm_id))%>% pivot_longer(cols=c("TOC")) %>% 
    screeningmodeling(values=value,
                    datevar = sampling_date, 
                    link = "identity", 
                    conf.type = "conf",
                    conf.level=0.95,
                    beep = FALSE, 
                    tdist = FALSE,
                    autocor = TRUE,
                    mvm_id,
                    x,
                    stationName) ->
  trendplotdata_selected_TOC
  trendplotdata_selected_TOC %>% left_join(coordinates) %>% saveRDS(., file = "data/trendplotdata_selected_TOC.rds")
  }  else if (re.read == 're load') {
    trendplotdata_selected_TOC <- readRDS( file = "data/trendplotdata_selected_TOC.rds")
  }
```

```{r}
#| include: false

if (re.read != 're fig' & exists("trendplotdata_selected_TOC")){
  fig <- trendplotdata_selected_TOC %>%plot_proportions()+ ggtitle("TOC") + 
        theme(text=element_text(size=5), #change font size of all text
        axis.text=element_text(size=5), #change font size of axis text
        axis.title=element_text(size=6), #change font size of axis titles
        plot.title=element_text(size=6.5), #change font size of plot title
        legend.text=element_text(size=6), #change font size of legend text
        legend.title=element_text(size=5)) 
  fig %>% ggsave(file = "figures/TOC_proportion_selected.png", width = 10,
  height = 6,
  units = "cm",
  dpi = 300) 
}  
```

```{r}
#| echo: false
#| fig-cap: "Proportion plot of TOC trends across Sweden. Updated from Eklöf et al, 2020."
#| fig-subcap:
#|        - "Using all 316 stations that fit the selection criteria of 10+ years of TOC data and < 5 percent urban area."
#|        - "Using 136 stations for which charge density was sucessfully calculated for."
#| fig-alt: TOC proportion of trends plot.
#| label: fig-TOC-prop1
#| layout-ncol: 2
knitr::include_graphics(path = c("figures/TOC_proportion.png","figures/TOC_proportion_selected.png"), error = FALSE)
```

```{r}
#| include: false
#Trend plot for TOC

if (re.read != 're fig' & exists("trendplotdata_selected_TOC")){
  fig <- trendplotdata_selected_TOC%>%plot_screeningtrends(y_id = mvm_id, sorting = -y) + ggtitle("TOC")+ xlab(NULL) + 
        theme(text=element_text(size=5), #change font size of all text
        axis.text=element_text(size=3), #change font size of axis text
        axis.title=element_text(size=6), #change font size of axis titles
        plot.title=element_text(size=6.5), #change font size of plot title
        legend.text=element_text(size=3), #change font size of legend text
        legend.title=element_text(size=3.5),
        legend.key.size = unit(0.3, 'cm'))
  fig %>% ggsave(plot = ., file = "figures/TOC_lasange_selected.png", width = 5,
  height = 20,
  units = "cm",
  dpi = 300)
} 
```
```{r}
#| echo: false
#| fig-cap: "Lasange plot of TOC trends across Sweden. Updated from Eklöf et al, 2020. Using 136 stations for which charge density was sucessfully calculated for."
#| fig-subcap:
#|        - "Using all 316 stations that fit the selection criteria of 10+ years of TOC data and < 5 percent urban area."
#|        - Using 136 stations for which charge density was sucessfully calculated for.
#| fig-alt: TOC proportion of trends plot.
#| label: fig-TOC-lasnage
#| layout-ncol: 2
#| fig-height: 8
knitr::include_graphics(path = c("figures/TOC_lasange.png","figures/TOC_lasange_selected.png"), error = FALSE)
```

---


## Methodology
The following steps were performed to get final values of charge density (charge per mg of carbon). 

1.  Raw water chemistry downloaded from the MVM database, for all streams in the database that had at least 10 years of continuous monthly sampling of TOC in the period 1990-2023. 
2.  Preprocessing of water chemistry data to aggregate different measurnment methods for the same variable into single columns. Here samples which did not have enough other parameters measured that were needed in the following steps were dropped from the analysis. Which parameters were deemed necessary is further elaborated in Section Visual Minteq. 
3. Modelling of DOC charge density in Visual Minteq by sweeping through the ADOM/DOC parameter for each sample, calculating charge difference for each ADOM/DOC. 
4. Processing of Visual Minteq output to find the ADOM/DOC that best models the chemical equiblirum for each sample with the smallest charge difference and use it to calculate the charge density of each sample.
5. Collection of catchment characteristics of the stations. 
6. Statistical Analysis looking at both spatial and temporal variation of DOC charge density across the dataset.  

---

# Data source


- Downloaded 114 320 samples from [MVM Database](https://miljodata.slu.se/MVM/)
- Stations were preselected for streams that had TOC sampled 10 times a year for at least 10 consecutive years since 1990. 
- Stations with more than 5% Urban area were excluded from the download. 
- Data for 316 stations were downloaded of these 136 were used in the end as they had data from SLU's lab and could be sufficiently modelled using Visual Minteq and are shown on a map @fig-map-stations, while the number of samples available are shown in @fig-hist_stations.
 
```{r}
#| echo: false
#| fig-cap: 136 stations with available data that were sucessfully modelled in this study. The size of the marker is related to the size of the color while the color shows the mean specific discharge (left), the annual precipitation (middle), and the annual mean tempertaur(right) of the catchment of the station.
#| fig-alt: Map of stations
#| label: fig-map-stations
#| out-width: 100%
#| cache-refresh: true
knitr::include_graphics("../results/reports/maps/map_stations.png")
```

---

# Preprocessing

- 42 907 samples across 187 stations meet the requirments for Visual Minteq.
- Median number of samples per station: 208
- In addition we removed all samples that were not analyzed in the SLU lab (some samples did not have the field analysis lab field filled in. These were also excluded.) 

```{r}
#| echo: false
#| fig-width: 5 
#| fig-height: 4
#| fig-cap: Histogram of number of samples per station used in further analysis. There are 42 907 samples across 187 stations. In further analysis only stations with more than 5 samples were considered, reducing the number of stations to 173.
#| fig-alt: Histogram of number of samples per station
#| label: fig-hist_stations 
#| cache-refresh: false

library(tidyverse)

sample_ids <- read.csv("../results/chemistry/slu_sample_ids.csv") %>% rename(sample_id =`SLU_sampleId`) # these are all the smaple id's of samples that were analysed at the SLU lab
data <- read.csv("../results/chemistry/complete.csv")
mvm_ids <- unique(data$mvm_id)
stations <- read.csv("../input/catchment_characteristics/catch_landuse(NMD).csv") %>% select(mvm_id, area_ARO_m2,stationCoordinateX, stationCoordinateY, stationName) %>% left_join(read.csv("../input/catchment_characteristics/catch_316_outlet_elevation.csv") %>%
      rename(elevation = elev_utl) %>%
      select(mvm_id, elevation))


# For all the labs, not applicable anymore 
# data %>% select(mvm_id) %>%
#   group_by(mvm_id) %>%
#   arrange(mvm_id) %>%       # Ensure data is ordered within each mvm_id (if needed)
#   slice(1) %>%             # take the first row of each group
#   ungroup() %>% left_join(stations) %>% left_join(mvm_counts) %>% filter(sample_count >= 5) -> stations_all

# Step 1: Count rows for each mvm_id
mvm_counts <- data %>%
  group_by(mvm_id) %>%
  summarise(sample_count = n())
  
# Lets have a look at the stations when we exclude the samples that are not measured at SLU
data %>% filter(sample_id %in% sample_ids$sample_id)%>% select(mvm_id) %>%
  group_by(mvm_id) %>%
  arrange(mvm_id) %>%       # Ensure data is ordered within each mvm_id (if needed)
  slice(1) %>%             # take the first row of each group
  ungroup() %>% left_join(stations) %>% left_join(mvm_counts) %>% filter(sample_count >= 5) -> stations


mvm_ids <- stations$mvm_id

data %>% filter(mvm_id %in% mvm_ids) -> data

data %>% mutate(EC_mS_m = coalesce(Kond_25_mSm, Kond_mSm, Kond_20_mSm, NA))-> data



# Step 2: Plot histogram of row counts
ggplot(mvm_counts, aes(x = sample_count)) +
  geom_histogram(binwidth = 12, fill = "skyblue", color = "black", alpha = 0.7) +
  labs(title = "",
       x = "Samples per station",
       y = "Frequency") +
  theme_minimal()
```

# Visual Minteq

## Required parameters

- silicon set to same value as in Sjösted et al, 2010: 0.01mM were it was not measured.

- bold parameters had to be measured parameters in the raw data, other parameters were set to 0 were not measured.

| Name        | Var           | Valance |
|-------------|---------------|---------|
| **Aluminium**   | Al_mol        |         |
| Copper      | Cu_mol        | +3      |
| Manganese   | Mn_mol        | +2      |
| **TOC**         | TOC_mol       | -x      |
| Zinc        | Zn_mol        |         |
| **SO4**         | SO4_mol       | -2      |
| **NO3**         | NO3_N_mol     | -1      |
| **Cl**          | Cl_alk_mol    | -1      |
| **Pottasium**   | K_mol         | +1      |
| **Calcium**     | Ca            | +2      |
| **Sodium**      | Na_acid_mol   | +1      |
| **Magnesium**   | Mg            | +2      |
| Iron        | Fe            | +3      |
| **Silicon**     | Si            |         |
| Ammonium    | NH4           | +1      |
| Fluorid     | F             | -1      |


## Modelling Set-up

- temperature set to 10°C
- pH 5.6
- Ferrihydrite as possible solid phase
- AlOH3 as possible solid phase
- ADOM/DOC sweep from 0.05 to 3.5
- alkalinity/acidity was added as Na and Cl concentration respectively. 

---

# Post Processing

For each sample the ADOM/DOC was selected that had the minimum absolute value of charge difference. Charge difference was calculated according to Visual Minteq as: 

$$
\text{Charge difference (\%)} = 100 \times \left| \frac{\text{SumA} - \text{SumC}}{\text{SumA} + \text{SumC}} \right|
$$


Visual Minteq uses ADOM/DOC to model the charge on the organic matter for each sample. Once the ADOM/DOC was determined for each sample the corresponding organic charge was used to calculate the charge density.


--- 

## ADOM/DOC
```{r}
#| fig-cap: Histogram of ADOM/DOC for samples before and after filtering for 173 stations (number of samples > 5).  
#| fig-alt: Histogram of ADOM/DOC.
#| label: fig-hist_adom_doc_after
#| fig-subcap:
#|    - Before filtering of charge difference < 0.5%
#|    - After filtering of charge difference < 0.5%
#| layout-ncol: 2

ggplot(data, aes(x = adom_doc)) +
  geom_histogram(binwidth = 0.05, fill = "skyblue", color = "black", alpha = 0.7) +
  labs(title = paste("Number of samples: ", nrow(data)),
       x = "ADOM/DOC",
       y = "Frequency") +
  theme_minimal()

ggplot(data %>% filter(abs(charge_diff) < 0.5), aes(x = adom_doc)) +
  geom_histogram(binwidth = 0.05, fill = "skyblue", color = "black", alpha = 0.7) +
  labs(title = paste("Number of samples: ", nrow(data %>% filter(abs(charge_diff) < 0.5))),
       x = "ADOM/DOC",
       y = "Frequency") +
  theme_minimal()
```

## Charge density

Charge density was calculated using the organic charge of the best fit ADOM/DOC for each sample and the concentration of TOC of the sample.

$$
\text{Charge density (eq/mg C)} = \left| \frac{\text{organic charge (eq/l)}}{\text{TOC (mg/l)}} \right|
$$

```{r}
#| fig-cap: Histogram of charge density for samples before and after filtering. 
#| fig-alt: Histogram of charge density.
#| label: fig-hist_cd_after
#| fig-subcap:
#|    - Before filtering of charge difference < 0.5%
#|    - After filtering of charge difference < 0.5%
#| layout-ncol: 2
ggplot(data, aes(x = org_charge_eq_mg_C)) +
  geom_histogram(fill = "skyblue", color = "black", alpha = 0.7) +
  labs(title = "",
       x = "charge density (charge/ mg C)",
       y = "Frequency") +
  theme_minimal()

ggplot(data %>% filter(abs(charge_diff) < 0.5), aes(x = org_charge_eq_mg_C)) +
  geom_histogram(fill = "skyblue", color = "black", alpha = 0.7) +
  labs(title = "",
       x = "charge density (charge/ mg C)",
       y = "Frequency") +
  theme_minimal()
```

---


# Catchment Characteristics

---

## Soil Depth

[SGU SOil Depth Raster map](https://www.sgu.se/en/products/maps/map-viewer/jordkartvisare/soil-depth/)

```{r}
library(tidyverse)
soil_depth <- read.csv("../input/catchment_characteristics/soil_depth.csv") %>% mutate(soil_depth_iqr = X75th_percentile - X25th_percentile, soil_depth_mean = mean) %>% select(mvm_id, soil_depth_iqr, soil_depth_mean) %>% filter(mvm_id %in% mvm_ids)%>% mutate(mvm_id = as.factor(mvm_id))
```

## Landuse

[NMD Land use data](https://www.naturvardsverket.se/4a43ca/contentassets/37e8b38528774982b5840554f02a1f81/produktbeskrivning-nmd-2018-basskikt-v2-2.pdf)

```{r}
landuse <- read.csv("../input/catchment_characteristics/PLC8_landuse.csv") %>% filter(mvm_id %in% mvm_ids) %>% mutate(mvm_id = as.factor(mvm_id))
```

## Climate

[SMHI PT-HBV Climate drided data](https://www.smhi.se/data/ladda-ner-data/griddade-nederbord-och-temperaturdata-pthbv)


```{r}
#| fig-cap: Histogram of climate variables.
#| label: fig-climate 
#| fig-subcap:
#|    - mean annual temperature
#|    - total annual precipitation
#| fig-alt: Histogram of temp & precip.
#| layout-ncol: 2

climate <- read.csv("../input/climate/daily_climate.csv") %>% filter(mvm_id %in% mvm_ids) %>% mutate(date = as.Date(time), year = year(date)) %>% filter (year >= 1990)  %>% group_by(mvm_id, year) %>% summarise(mean_annual_temp = mean(tas_avg), annual_precip= sum(pr_avg)) %>% ungroup() %>% group_by(mvm_id) %>% summarise(mean_annual_temp = mean(mean_annual_temp), annual_precip= mean(annual_precip)) %>% ungroup() %>% mutate(mvm_id = as.factor(mvm_id))

ggplot(climate, aes(x = mean_annual_temp)) +
  geom_histogram(fill = "skyblue", color = "black", alpha = 0.7) +
  labs(title = "",
       x = "mean annual temperature (C)",
       y = "Frequency") +
  theme_minimal()

ggplot(climate, aes(x = annual_precip)) +
  geom_histogram(fill = "skyblue", color = "black", alpha = 0.7) +
  labs(title = "",
       x = "total annual precipitation (mm)",
       y = "Frequency") +
  theme_minimal()
```

```{r}

climate_p1 <- read.csv("../input/climate/daily_climate.csv") %>% filter(mvm_id %in% mvm_ids) %>% mutate(date = as.Date(time), year = year(date)) %>% filter (year >= 1990 & year < 1998)  %>% group_by(mvm_id, year) %>% summarise(mean_annual_temp = mean(tas_avg), annual_precip= sum(pr_avg)) %>% ungroup() %>% group_by(mvm_id) %>% summarise(mean_annual_temp = mean(mean_annual_temp), annual_precip= mean(annual_precip)) %>% ungroup() %>% mutate(mvm_id = as.factor(mvm_id)) %>% mutate(period = "1990-1997")

climate_p2 <- read.csv("../input/climate/daily_climate.csv") %>% filter(mvm_id %in% mvm_ids) %>% mutate(date = as.Date(time), year = year(date)) %>% filter (year >= 1998 & year < 2012)   %>% group_by(mvm_id, year) %>% summarise(mean_annual_temp = mean(tas_avg), annual_precip= sum(pr_avg)) %>% ungroup() %>% group_by(mvm_id) %>% summarise(mean_annual_temp = mean(mean_annual_temp), annual_precip= mean(annual_precip)) %>% ungroup() %>% mutate(mvm_id = as.factor(mvm_id)) %>% mutate(period = "1998-2011")

climate_p3 <- read.csv("../input/climate/daily_climate.csv") %>% filter(mvm_id %in% mvm_ids) %>% mutate(date = as.Date(time), year = year(date)) %>% filter (year >= 2012 & year < 2025)  %>% group_by(mvm_id, year) %>% summarise(mean_annual_temp = mean(tas_avg), annual_precip= sum(pr_avg)) %>% ungroup() %>% group_by(mvm_id) %>% summarise(mean_annual_temp = mean(mean_annual_temp), annual_precip= mean(annual_precip)) %>% ungroup() %>% mutate(mvm_id = as.factor(mvm_id)) %>% mutate(period = "2012-2024")

climate_all <- bind_rows(climate_p1, climate_p2, climate_p3)

# Reshape the data to long format
climate_long <- climate_all %>%
  pivot_longer(cols = c(mean_annual_temp, annual_precip),
               names_to = "variable", values_to = "value")

# Create boxplots with separate panels
# ggplot(climate_long, aes(x = period, y = value, fill = period)) +
#   geom_boxplot() +
#   facet_wrap(~ variable, scales = "free_y") +
#   labs(title = "Boxplots of Climate Variables Across Periods",
#        x = "Period", y = "Value") +
#   theme_minimal()


library(ggpubr)


my_comparisons <- list( c("1990-1997", "1998-2011"), c("1998-2011", "2012-2024"), c("1990-1997", "2012-2024") )

```

```{r}
#| eval: true
#| fig-cap: Boxplots of climate variables for the three periods 1990-1997, 1998-2011, 2012-2024.
#| label: fig-climate-periods 
#| fig-subcap:
#|    - Change in mean annual temperature for the three periods. Temperature was not significantly differnt in the three periods
#|    - Change in annual precipitation for the three periods 1990-1997, 1998-2011, 2012-2024. 1998-2011 was found to be significantly higher in precipitation than the earlier and later periods. 
#| fig-alt: Climate change in the three periods.
#| layout-ncol: 2
ggboxplot(climate_all ,x = "period", y = "mean_annual_temp",
          color = "period", palette = "jco")+ 
  stat_compare_means(comparisons = my_comparisons, paired = TRUE)+ # Add pairwise comparisons p-value
  stat_compare_means(label.y = 13) 

ggboxplot(climate_all ,x = "period", y = "annual_precip",
          color = "period", palette = "jco")+ 
  stat_compare_means(comparisons = my_comparisons, paired = TRUE)+ # Add pairwise comparisons p-value
  stat_compare_means(label.y = 1650) 
```


## Discharge

[SMHI S-HYPE](https://www.smhi.se/data/hydrologi/vattenwebb/data-for-delavrinningsomraden-sotvatten-1.118236)

Area proportional discharge calculated for each station, using the local discharge when considering sub-cacthments of the SMHI unit catchments (Aroid catchments), and total when the SMHI subcatchment is smaller than the station catchment. Were possible upstream station corrected discharge was used.   
c
Discharge is in m3/s and specific discharge in mm/day. 
```{r}
#| fig-cap: Discharge for all catchments in the DOC dissociation study. 
#| fig-alt: Histogram of charge density.
#| label: fig-discharge
#| fig-subcap:
#|    - Boxplot of all the catchments together.
#|    - Example of median annual discharge for 4 different catchments.
#| layout-ncol: 2
discharge <- read.csv("../input/discharge/daily_discharge.csv") %>% filter(mvm_id %in% mvm_ids) %>% mutate(date = as.Date(Datum), year = year(date)) %>% group_by(mvm_id, year) %>% summarise(median_q_m3_s = median(q), p25_q_m3_s  = quantile(q, probs = 0.25, na.rm = TRUE) , p75_q_m3_s = quantile(q, probs = 0.75, na.rm = TRUE)) %>% ungroup() %>% left_join(stations)%>% mutate(mvm_id = as.factor(mvm_id)) 

ggplot(discharge, aes(group = year, x = year, y = log(median_q_m3_s))) +
geom_boxplot()

ggplot(discharge %>% filter (mvm_id %in% c(21, 180,33,222 )) %>% mutate(q_spec= (median_q_m3_s / area_ARO_m2)*1000*60*60*24), aes( x = year, y = q_spec, color = mvm_id)) +
geom_line()+
labs( y = "Specific discharge (mm/s)")

discharge %>% mutate(q_spec= (median_q_m3_s / area_ARO_m2)*1000*60*60*24, p25_spec = (p25_q_m3_s / area_ARO_m2)*1000*60*60*24, p75_spec = (p75_q_m3_s / area_ARO_m2)*1000*60*60*24 ) %>%
group_by(mvm_id) %>% summarise(
    mean_Q_spec = mean(q_spec), p25_Q_spec = mean(p25_spec), p75_Q_spec = mean(p75_spec), mean_Q = mean(median_q_m3_s)) %>% ungroup() -> discharge_y
```


```{r}
#| fig-cap: Change in discharge for the three periods 1990-1997, 1998-2011, 2012-2024.
#| label: fig-discharge-periods 
#| fig-subcap:
#|    - mean annual discharge
#|    - 25% discharge
#|    - 75% discharge
#| fig-alt: Climate change in the three periods.
#| layout-ncol: 2
discharge %>% mutate(q_spec= (median_q_m3_s / area_ARO_m2)*1000*60*60*24, p25_spec = (p25_q_m3_s / area_ARO_m2)*1000*60*60*24, p75_spec = (p75_q_m3_s / area_ARO_m2)*1000*60*60*24 ) %>% filter((year >= 1990 & year < 1998) ) %>%
group_by(mvm_id) %>% summarise(
    log_mean_Q_spec = mean(log(q_spec)), log_p25_Q_spec = mean(log(p25_spec)), log_p75_Q_spec = mean(log(p75_spec)), log_mean_Q = mean(log(median_q_m3_s)))  %>% ungroup() %>% mutate(period = "1990-1997") -> discharge_p1

discharge %>% mutate(q_spec= (median_q_m3_s / area_ARO_m2)*1000*60*60*24, p25_spec = (p25_q_m3_s / area_ARO_m2)*1000*60*60*24, p75_spec = (p75_q_m3_s / area_ARO_m2)*1000*60*60*24 ) %>% filter((year >= 1998 & year < 2012) ) %>%
group_by(mvm_id) %>% summarise(
    log_mean_Q_spec = mean(log(q_spec)), log_p25_Q_spec = mean(log(p25_spec)), log_p75_Q_spec = mean(log(p75_spec)), log_mean_Q = mean(log(median_q_m3_s)))  %>% mutate(period = "1998-2011") -> discharge_p2

discharge %>% mutate(q_spec= (median_q_m3_s / area_ARO_m2)*1000*60*60*24, p25_spec = (p25_q_m3_s / area_ARO_m2)*1000*60*60*24, p75_spec = (p75_q_m3_s / area_ARO_m2)*1000*60*60*24 ) %>% filter((year >= 2012 & year < 2024) ) %>%
group_by(mvm_id) %>% summarise(
    log_mean_Q_spec = mean(log(q_spec)), log_p25_Q_spec = mean(log(p25_spec)), log_p75_Q_spec = mean(log(p75_spec)), log_mean_Q = mean(log(median_q_m3_s))) %>% ungroup() %>% mutate(period = "2012-2024") -> discharge_p3


discharge_all <- bind_rows(discharge_p1, discharge_p2, discharge_p3)

# Reshape the data to long format
discharge_long <- discharge_all %>%
  pivot_longer(cols = c(log_mean_Q_spec ,log_p25_Q_spec, log_mean_Q),
               names_to = "variable", values_to = "value")

# Create boxplots with separate panels
ggplot(discharge_long, aes(x = period, y = value, fill = period)) +
  geom_boxplot() +
  facet_wrap(~ variable, scales = "free_y") +
  labs(title = "Boxplots of Climate Variables Across Periods",
       x = "Period", y = "Value") +
  theme_minimal()


library(ggpubr)


# my_comparisons <- list( c("1990-1997", "1998-2011"), c("1998-2011", "2012-2024"), c("1990-1997", "2012-2024") )
# ggboxplot(discharge_all ,x = "period", y = "log_p25_Q_spec",
#           color = "period", palette = "jco")+ 
#   stat_compare_means(comparisons = my_comparisons, paired = TRUE)+ # Add pairwise comparisons p-value
#   stat_compare_means(label.y = -4)     # Add global p-value

# ggboxplot(discharge_all ,x = "period", y = "log_mean_Q_spec",
#           color = "period", palette = "jco") + 
#   stat_compare_means(comparisons = my_comparisons, paired = TRUE)+ # Add pairwise comparisons p-value
#   stat_compare_means(label.y = -4) 

# ggboxplot(discharge_all ,x = "period", y = "log_mean_Q",
#           color = "period", palette = "jco") + 
#   stat_compare_means(comparisons = my_comparisons, paired = TRUE)+ # Add pairwise comparisons p-value
#   stat_compare_means(label.y = 11) 
```


<!-- https://www.datanovia.com/en/lessons/friedman-test-in-r/ -->
```{r}
#| eval: false
library(rstatix)

friedman.test(log_mean_Q ~ period | mvm_id, data = discharge_all)

friedman_effsize(log_mean_Q ~ period | mvm_id, data = discharge_all)

discharge_all

pwc <- discharge_all %>%
  wilcox_test(log_mean_Q ~ period, paired = TRUE, p.adjust.method = "bonferroni")
```


## NDVI

[NDVI](https://www.usgs.gov/landsat-missions/landsat-normalized-difference-vegetation-index)

Extracted using GGE for monthly time series for each catchment of median NDVI from the Landcare compiled NDVI images. These are taken at a 8 day interval since before 1990 using 4 different landsat sattelites. The compiled dataset was used as NDVI data was preprocessed and alignesd between the different sattelites.

```{r}
#| eval: false

# this is the code for aggregating all the NDVI files for each catchment and putting it into a single file. 

folder_path <- '/mnt/c/Temp/Offline_temp/NDVI_Results_individual'

csv_files <- list.files(path = folder_path, pattern = "\\.csv$", full.names = TRUE)

# Read and combine all CSV files into one data frame
combined_df <- csv_files %>%
  map_dfr(read_csv)

# Print the first few rows of the combined data frame
print(head(combined_df))

combined_df %>% write.csv(file = "../input/catchment_characteristics/NDVI.csv", row.names = FALSE)
```

```{r}
#| fig-cap: Summer NDVI June-August for all catchments in the DOC dissociation study. 
#| fig-alt: NDVI.
#| label: fig-ndvi
#| fig-subcap:
#|    - Boxplot of all the catchments together.
#|    - Example of summer NDVI for 4 different catchments.
#| cache-refresh: false

ndvi <- read.csv("../input/catchment_characteristics/NDVI.csv")  %>% filter(mvm_id %in% mvm_ids) %>% mutate(date = make_date(year,month,15)) %>% filter (month %in% c(6,7,8)) %>% group_by(mvm_id, year) %>% summarise(summer_NDVI = mean(NDVI_median, na.rm = TRUE)) %>% ungroup() %>% mutate(mvm_id = as.factor(mvm_id)) 

ggplot(ndvi, aes(group = year, x = year, y = summer_NDVI)) +
geom_boxplot()

ggplot(ndvi %>% filter (mvm_id %in% c(21, 180,33,222 )), aes( x = year, y = summer_NDVI, color = mvm_id)) +
geom_line()

ndvi_y <- ndvi %>% group_by(mvm_id)%>% summarise(summer_NDVI = mean(summer_NDVI, na.rm = TRUE)) %>% ungroup()
```

```{r}
#| fig-cap: Summer NDVI June-August for all catchments in the DOC dissociation study for the periods 1990-1997, 1998-2011, 2012-2024. 
#| fig-alt: NDVI comparison.
#| label: fig-ndvi.comp
#| cache-refresh: false

ndvi  %>% filter((year >= 1990 & year < 1998) ) %>%
group_by(mvm_id) %>% summarise(summer_NDVI = mean(summer_NDVI, na.rm = TRUE))  %>% ungroup() %>% mutate(period = "1990-1997") -> ndvi_p1

ndvi  %>% filter((year >= 1998 & year < 2012) ) %>%
group_by(mvm_id) %>% summarise(summer_NDVI = mean(summer_NDVI, na.rm = TRUE))  %>% mutate(period = "1998-2011") -> ndvi_p2

ndvi %>%  filter((year >= 2012 & year < 2024) ) %>%
group_by(mvm_id) %>% summarise(summer_NDVI = mean(summer_NDVI, na.rm = TRUE)) %>% ungroup() %>% mutate(period = "2012-2024") -> ndvi_p3

ndvi_periods <- rbind(ndvi_p1, ndvi_p2, ndvi_p3)

library(ggpubr)


my_comparisons <- list( c("1990-1997", "1998-2011"), c("1998-2011", "2012-2024"), c("1990-1997", "2012-2024") )

ggboxplot(ndvi_periods %>% filter(mvm_id != 43) ,x = "period", y = "summer_NDVI",
          color = "period", palette = "jco") + 
  stat_compare_means(comparisons = my_comparisons, paired = TRUE)+ # Add pairwise comparisons p-value
  stat_compare_means(label.y = 1.05)
```


## Peat Area

[SLU Peat Map](https://www.slu.se/en/environment/statistics-and-environmental-data/search-for-open-environmental-data/comprehensive-peat-map-of-the-forest-land/#downloadInfo)

Peat is considered >30cm peat depth.  

```{r}
#| fig-cap: Peat area data from the slu peat map. 
#| fig-alt: Peat area
#| label: fig-peat
#| 
peat <- read.csv("../input/catchment_characteristics/peat_area.csv") %>% rename(water = X0, mineral_soil = X1, peat_a30 = X2, peat_a40 = X3, peat_a50 = X4) %>% mutate(peat = ((peat_a30 + peat_a40 + peat_a50) / sum), water = (water / sum), mineral_soil = (mineral_soil / sum )) %>% select(peat, mvm_id, water, mineral_soil)%>% filter(mvm_id %in% mvm_ids)  %>% mutate(mvm_id = as.factor(mvm_id))

df_long <- peat %>%
  pivot_longer(
    cols = c(mineral_soil, water, peat),
    names_to = "Variable",
    values_to = "Value"
  )

ggplot(df_long, aes(x = Variable, y = Value, fill = Variable)) +
  geom_boxplot() +
  theme_minimal() +
  labs(
    title = "",
    x = "Variable",
    y = "% cover"
  ) 
```

---



## Summary

Most are given as the percenctage of the area in the catchment covered by the specific data source. Exeptions are:  

- Temperature i.e. MAT (mean annual average in °C)
- Discharge (annual and interquantile range average m3/s)
- Precipitation (mm/year), summer NDVI (NDVI for mean of June July and August for every year averaged over the time period 1990-2023)
- Specific discharge mean, p25, p75, (extracted median, p75, p25 for each year and then averaged them over the entire time period. mm/s)


```{r}
#| cache-refresh: false
#| label: tbl-catch_char
#| tbl-cap: Catchment characteristics for the stations used in this study.

catch_char <- landuse %>% 
        left_join(peat %>% select(-water), by = join_by(mvm_id)) %>%
        left_join(soil_depth, by = join_by(mvm_id)) %>%
        left_join(climate, by = join_by(mvm_id))%>% 
        left_join(ndvi_y, by = join_by(mvm_id)) %>%
        left_join(discharge_y) %>% 
        left_join(stations %>% select(-sample_count ) %>% mutate(mvm_id = as_factor(mvm_id))) %>% 
        mutate(log_mean_Q = log(mean_Q)) %>% select(-mean_Q)

library(vtable)

sumtable(catch_char %>% select(-mvm_id), out ="kable", digits = 3) # %>% kable_styling(font_size = 10)
```

---

# Water Chemistry

In this section we test for normality of the data, compare the variation within stations and between stations and look at correlations betweeen the different water chemistry variables. For this we use the data of the 136 stations for which we sucessfully modelled organic charge. 

```{r}
#| cache-refresh: false
data %>% filter(abs(charge_diff) < 0.5) %>% mutate(sVISa = Abs_F420_5cm/(TOC_mol*12.01*1000)) -> data
data %>% mutate(year = year(sampling_date), TOC_mg_l = TOC_mol*12.01*1000, org_charge_density_meq_g_C = org_charge_eq_mg_C * 1000*1000,`Al3+ (µmol/l)` = Al.3 *1000000, `Si (mmol/l)` = Si_mol* 1000, `Cl (mmol/l)` = Cl_mol*1000, `Al total (µmol/l)` = Al_mol * 1000000, `F (µmol/l)` = Fluorid_mol *1000000) %>% select(year,EC_mS_m, sVISa,org_charge_density_meq_g_C,TOC_mg_l,SO4_mol,Alk_Acid_mol, sampling_date, Abs_F420_5cm, mvm_id, adom_doc, charge_diff, org_charge, Sum.of.cations, pH_, Ionic.strength, sample_id, `Al3+ (µmol/l)`, `Si (mmol/l)`, `Cl (mmol/l)`,`Al total (µmol/l)`,`F (µmol/l)`) -> data_1
```

```{r}
#| label: calc-weigths
library(dplyr)
library(ggplot2)
library(matrixStats)
library(PSCBS)

# Calculate the weights for each station
weights <- data_1 %>%
  group_by(mvm_id) %>%
  summarise(weight = 1 / n()) %>%
  ungroup()

# Merge weights with the original data
data_1_with_weights <- data_1 %>%
  left_join(weights, by = "mvm_id")
```



```{r}
#| cache-refresh: true
#| label: tbl-chemistry
#| tbl-cap: Water chemistry values measured and modelled for the stations used in this study, weighted porportional to number of samples for each station. 
library(vtable)
library(matrixStats)
sumtable(data_1_with_weights %>% mutate(
  `SO4 (mmol/l)` = SO4_mol *1000,
  `Alk Acid (mmol/l)` = Alk_Acid_mol *1000,
  `Organic charge (meq/l)` = org_charge*1000, 
  `Sum of Cations (mmol/l)` = Sum.of.cations*1000
  )%>% select(-c(
    SO4_mol, charge_diff, Alk_Acid_mol, org_charge, Sum.of.cations, sample_id, mvm_id, weight
    )) %>% rename(
      `TOC (mg/l)` = TOC_mg_l,
      `Org. Charge Density (meq/g of C)` = org_charge_density_meq_g_C,
      `EC (mS/M)` = EC_mS_m,
      `Absorbance 420mm` = Abs_F420_5cm, 
      `ADOM/DOC` = adom_doc,
      `Ionic strength` = Ionic.strength, 
      `Field pH` = pH_
    ), out = "kable", group.weights = data_1_with_weights$weight,summ=c('notNA(x)',
                'reldist::wtd.quantile (x, q=0.50, na.rm = TRUE, weight = wts)',
                'reldist::wtd.quantile (x, q=0.75, na.rm = TRUE, weight = wts) - reldist::wtd.quantile (x, q=0.25, na.rm = TRUE, weight = wts)', 'reldist::wtd.quantile (x, q=0, na.rm = TRUE, weight = wts)', 'reldist::wtd.quantile (x, q=1, na.rm = TRUE, weight = wts)'), summ.names = c("N", "Median", "IQR", "min", "max")) # %>% kable_styling(font_size = 10)
```



---

## Normality

Here we plot the histogram and Q-Q plots for the main water chemistry parameters. 

```{r}
plot_norm <- function(var, name = "Variable", breaks = 100){
  hist(var, breaks = breaks, main = "", xlab = name)
  qqnorm(var, main = "")
  qqline(var)
}
```

---

### sVISa

```{r}
#| fig-cap: sVISA distribution
#| fig-subcap:
#|        - "Histogram of sVISa"
#|        - "QQ-plot"
#| label: fig-norm-sVISa
#| layout-ncol: 2
plot_norm(data_1$sVISa, name = "sVISa")
```

### TOC

TOC is not normally distributed, though I would say when log transformed it is close enough to a normal distribution to warrant a parametric test.

```{r}
#| fig-cap: TOC distribution
#| fig-subcap:
#|        - "Histogram of TOC"
#|        - "QQ-plot"
#| label: fig-norm-TOC
#| layout-ncol: 2
plot_norm(data_1$TOC_mg_l, name = "TOC (mg/l)")
```
```{r}
#| fig-cap: Log TOC distribution
#| fig-subcap:
#|        - "Histogram of log(TOC)"
#|        - "QQ-plot"
#| label: fig-norm-logTOC
#| layout-ncol: 2
plot_norm(log(data_1$TOC_mg_l), name = "log TOC (mg/l)")
```
### Organic charge density

For organic charge density I would also say that although it is not perfectly normally distributed I would say its close enough to a normal distribution that a parametric test is acceptable. Though a non-parametric test is also a good option. 

```{r}
#| fig-cap: Organic charge density distribution
#| fig-subcap:
#|        - "Histogram of Organic charge density"
#|        - "QQ-plot"
#| label: fig-norm-org-density
#| layout-ncol: 2
plot_norm(data_1$org_charge_density_meq_g_C, name = "Organic charge density (meq/g of C)")
```

```{r}
#| fig-cap: Logged Organic charge density distribution
#| fig-subcap:
#|        - "Histogram of log(Organic charge density)"
#|        - "QQ-plot"
#| label: fig-norm-org-density-log
#| layout-ncol: 2
plot_norm(log(-data_1$org_charge_density_meq_g_C), name = "log (Organic charge density (meq/g of C))")
```

### Conclusion

I would have said that they are all pretty close to normal distribution as long as we use log(TOC). They are not perfect though so a non-parametric test is also a good option to be safe. Since we have previously looked at this with Ted and agreed with him that a non-parametric test is appropriate I will go on using non-parametric tests and consider these not normally distributed. 

---



## Variation Comparison
```{r}
library(ggplot2)
library(tidyr)

plot_variable_distribution <- function(data, variable_name) {
  # Dynamically evaluate the variable column from the data
  aggregated_data <- aggregate(
    reformulate("mvm_id", variable_name),  # Use reformulate for dynamic column names
    data,
    function(x) {
      c(
        median = median(x, na.rm = TRUE),
        iqr = quantile(x, 0.75, na.rm = TRUE) - quantile(x, 0.25, na.rm = TRUE)
      )
    }
  )
  
  # Convert list columns into separate data frame columns
  aggregated_data <- do.call(data.frame, aggregated_data)
  names(aggregated_data) <- c("mvm_id", "median", "iqr")
  
  # Reshape the data to long format for ggplot
  long_data <- pivot_longer(
    aggregated_data,
    cols = c("median", "iqr"),
    names_to = "statistic",
    values_to = "value"
  )
  
  # Plot both distributions with a legend
  ggplot(long_data, aes(x = value, fill = statistic, color = statistic)) +
    geom_density(alpha = 0.4) +  # Transparency for overlapping areas
    labs(
      x = variable_name,
      y = "Density",
      fill = "Statistic",  # Legend title for the fill aesthetic
      color = "Statistic"  # Legend title for the color aesthetic
    ) +
    scale_fill_manual(values = c("lightblue", "orange")) +  # Custom colors
    scale_color_manual(values = c("blue", "darkorange")) +
    theme_minimal()
}
```

---

### TOC
```{r}
#| fig-cap: Boxplot for each of the stations sample distribution of TOC. The blue box is the weighted IQR for all the stations, with the red dashed line as the weighted median for all the stations. 
#| label: fig-variation-toc


# Calculate the weighted median, 25th percentile, and 75th percentile
weighted_median <- weightedMedian(data_1_with_weights$TOC_mg_l, w = data_1_with_weights$weight, na.rm = TRUE)
weighted_25th <- weightedQuantile(data_1_with_weights$TOC_mg_l, w = data_1_with_weights$weight, probs = 0.25, na.rm = TRUE)
weighted_75th <- weightedQuantile(data_1_with_weights$TOC_mg_l, w = data_1_with_weights$weight, probs = 0.75, na.rm = TRUE)

# Create the boxplot and add the horizontal lines for the weighted median, 25th, and 75th percentiles
data_1 %>%
  mutate(mvm_id = as.factor(mvm_id)) %>%
  ggplot(aes(x = mvm_id, y = TOC_mg_l)) +
  geom_rect(aes(xmin = -Inf, xmax = Inf, ymin = weighted_25th, ymax = weighted_75th), fill = "lightblue", alpha = 0.2) +
  geom_hline(yintercept = weighted_median, linetype = "dashed", color = "red") +
  geom_hline(yintercept = weighted_25th, linetype = "dotted", color = "blue") +
  geom_hline(yintercept = weighted_75th, linetype = "dotted", color = "blue") +
  theme_minimal() +
  theme(legend.position = "none") +
  geom_boxplot(outlier.shape = NA, alpha = 0.5 ) +
  labs(y = "TOC (mg/l)", x = "Station")+
  theme(axis.text.x = element_blank())
```

### sVISa
```{r}
#| fig-cap: Boxplot for each of the stations sample distribution of sVISa. The blue box is the weighted IQR for all the stations, with the red dashed line as the weighted median for all the stations. 
#| label: fig-variation-sVISa
# Calculate the weighted median, 25th percentile, and 75th percentile
weighted_median <- weightedMedian(data_1_with_weights$TOC_mg_l, w = data_1_with_weights$weight, na.rm = TRUE)
weighted_25th <- weightedQuantile(data_1_with_weights$TOC_mg_l, w = data_1_with_weights$weight, probs = 0.25, na.rm = TRUE)
weighted_75th <- weightedQuantile(data_1_with_weights$TOC_mg_l, w = data_1_with_weights$weight, probs = 0.75, na.rm = TRUE)

# Create the boxplot and add the horizontal lines for the weighted median, 25th, and 75th percentiles
data_1 %>%
  mutate(mvm_id = as.factor(mvm_id)) %>%
  ggplot(aes(x = mvm_id, y = TOC_mg_l)) +
  geom_rect(aes(xmin = -Inf, xmax = Inf, ymin = weighted_25th, ymax = weighted_75th), fill = "lightblue", alpha = 0.2) +
  geom_hline(yintercept = weighted_median, linetype = "dashed", color = "red") +
  geom_hline(yintercept = weighted_25th, linetype = "dotted", color = "blue") +
  geom_hline(yintercept = weighted_75th, linetype = "dotted", color = "blue") +
  theme_minimal() +
  theme(legend.position = "none") +
  geom_boxplot(outlier.shape = NA, alpha = 0.5 ) +
  labs(y = "TOC (mg/l)", x = "Station")+
  theme(axis.text.x = element_blank())
```

### Organic charge density
```{r}
#| fig-cap: Boxplot for each of the stations sample distribution of organic charge density. The blue box is the weighted IQR for all the stations, with the red dashed line as the weighted median for all the stations. 
#| label: fig-variation-org-charge-density

# Calculate the weighted median, 25th percentile, and 75th percentile
weighted_median <- weightedMedian(data_1_with_weights$org_charge_density_meq_g_C, w = data_1_with_weights$weight, na.rm = TRUE)
weighted_25th <- weightedQuantile(data_1_with_weights$org_charge_density_meq_g_C, w = data_1_with_weights$weight, probs = 0.25, na.rm = TRUE)
weighted_75th <- weightedQuantile(data_1_with_weights$org_charge_density_meq_g_C, w = data_1_with_weights$weight, probs = 0.75, na.rm = TRUE)

# Create the boxplot and add the horizontal lines for the weighted median, 25th, and 75th percentiles
data_1 %>%
  mutate( mvm_id = as.factor(mvm_id)) %>%
  ggplot(aes(x = mvm_id, y = org_charge_density_meq_g_C)) +
  geom_rect(aes(xmin = -Inf, xmax = Inf, ymin = weighted_25th, ymax = weighted_75th), fill = "lightblue", alpha = 0.2) +
  geom_hline(yintercept = weighted_median, linetype = "dashed", color = "red") +
  geom_hline(yintercept = weighted_25th, linetype = "dotted", color = "blue") +
  geom_hline(yintercept = weighted_75th, linetype = "dotted", color = "blue") +
  theme_minimal() +
  theme(legend.position = "none") +
  geom_boxplot(outlier.shape = NA, alpha = 0.5 ) +
  labs(y = "Org Charge Density (mmeq/g of C)", x = "Station")+
  theme(axis.text.x = element_blank())
```

### Organic charge

```{r}
#| fig-cap: Boxplot for each of the stations sample distribution of organic charge. The blue box is the weighted IQR for all the stations, with the red dashed line as the weighted median for all the stations. 
#| label: fig-variation-org-charge

# Calculate the weighted median, 25th percentile, and 75th percentile
weighted_median <- weightedMedian(data_1_with_weights$org_charge * 1000, w = data_1_with_weights$weight, na.rm = TRUE)
weighted_25th <- weightedQuantile(data_1_with_weights$org_charge * 1000, w = data_1_with_weights$weight, probs = 0.25, na.rm = TRUE)
weighted_75th <- weightedQuantile(data_1_with_weights$org_charge * 1000, w = data_1_with_weights$weight, probs = 0.75, na.rm = TRUE)

# Create the boxplot and add the horizontal lines for the weighted median, 25th, and 75th percentiles
data_1 %>%
  mutate(org_charge_mmol_l = org_charge * 1000, mvm_id = as.factor(mvm_id)) %>%
  ggplot(aes(x = mvm_id, y = org_charge_mmol_l)) +
  geom_rect(aes(xmin = -Inf, xmax = Inf, ymin = weighted_25th, ymax = weighted_75th), fill = "lightblue", alpha = 0.2) +
  geom_hline(yintercept = weighted_median, linetype = "dashed", color = "red") +
  geom_hline(yintercept = weighted_25th, linetype = "dotted", color = "blue") +
  geom_hline(yintercept = weighted_75th, linetype = "dotted", color = "blue") +
  theme_minimal() +
  theme(legend.position = "none") +
  geom_boxplot(outlier.shape = NA, alpha = 0.5 ) +
  labs(y = "Org Charge (mmol/l)", x = "Station")+
  theme(axis.text.x = element_blank())
```


---

```{r}
#| fig-cap: Comparison of the distribution of median values for each stations (blue) and inter quantile range (IQR, orange) for each station.
#| fig-subcap:
#|      - "sVISa median and IQR distributions"
#|      - "TOC median and IQR distributions"
#|      - "Organic charge density median and IQR distributions"
#|      - "Organic charge median and IQR distribution (in mmol of charge per litre"
#| label: fig-variation
#| layout-ncol: 2

plot_variable_distribution(data_1, "sVISa")
plot_variable_distribution(data_1, "TOC_mg_l")
plot_variable_distribution(data_1, "org_charge_density_meq_g_C")
plot_variable_distribution(data_1 %>% mutate(org_charge_mmol_l = org_charge *1000), "org_charge_mmol_l")
```


**So how big are these changes in charge density?**


```{r}
median_mg_TOC <- median(data$TOC_mol) *12.01 *1000 
median_charge_density <- median(data$org_charge_eq_mg_C)

median_organic_charge_meq <- median_charge_density * median_mg_TOC *1000

sd_organic_charge_meq <- sd(data$org_charge_eq_mg_C) * median_mg_TOC *1000
```

Taking the mean TOC concentration and median organic charge density of all samples we get a median organic charge of `{r} round(median_organic_charge_meq, digits = 3)` meq/l using the standard deviation of organic charge density and the median toc concentration we then get a standard deviation of organi charge of `{r} round(sd_organic_charge_meq, digits = 3)` meq/l. 


## Correlations

```{r}
#| fig-cap: "Correlation matrix using spearman (non-parametric) correlation to calculate correlation and significance of p < 0.05. Crossed out field indicate no significant correlation with p > 0.05. The area and color of the circle indicate the correlation coefficent."
#| label: fig-corrmatrix
#| out-width: 100%

library(corrplot)
library(Hmisc)

res2 <- rcorr(as.matrix(data_1 %>% select(-c(sampling_date, sample_id, mvm_id))), type = c("spearman"))

diag(res2$P) <- 0 # fill in the diagonal with 0 (perfect siginficance)

corrplot(res2$r, order="hclust", type = 'upper', p.mat = res2$P,sig.level = 0.05, insig = "pch", tl.col = "black", method = 'pie', outline = 'white', tl.cex = 0.5)
```

---

# Temporal Patters

For each individual catchemnt split into three time periods, has to have at least 2 years samples in each time period for it to work. 
The three periods are: 

- 1990-1997
- 1998-2012
- 2013-2024

For each stations we split the data into these three periods, then we test the data within each stations for changes between the periods using Kruskal-Wallis. 

```{r}
library(vtable)
data_periods <- data_1 %>% 
  mutate(
    period = case_when(
      sampling_date < as.Date("1998-01-01") ~ "1990-1997",
      sampling_date >= as.Date("1997-01-01") & sampling_date <= as.Date("2012-01-01") ~ "1998-2012",
      sampling_date > as.Date("2012-01-01") ~ "2012-2024",
      TRUE ~ NA_character_  # Handle any NA values if necessary
    )
  )

```

```{r}
#| cache-refresh: true
#| label: tbl-chemistry-periods
#| tbl-cap: Water chemistry values measured and modelled for the stations used in this study. Data from all stations is weighted to be proportional to the number of samples in each station, such that each station has the same weight.

library(dplyr)
library(ggplot2)
library(matrixStats)

# Add period column
data_periods <- data_1 %>% 
  mutate(
    period = case_when(
      sampling_date < as.Date("1998-01-01") ~ "1990-1997",
      sampling_date >= as.Date("1997-01-01") & sampling_date <= as.Date("2012-01-01") ~ "1998-2012",
      sampling_date > as.Date("2012-01-01") ~ "2012-2024",
      TRUE ~ NA_character_  # Handle any NA values if necessary
    )
  )

# Calculate the weights for each station within each period
weights <- data_periods %>%
  group_by(period, mvm_id) %>%
  summarise(weight = 1 / n()) %>%
  ungroup()

# Merge weights with the original data
data_with_weights <- data_periods %>%
  left_join(weights, by = c("period", "mvm_id"))

sumtable(data_with_weights %>% mutate(
  `SO4 (mmol/l)` = SO4_mol *1000,
  `Alk Acid (mmol/l)` = Alk_Acid_mol *1000,
  `Organic charge (meq/l)` = org_charge*1000, 
  `Sum of Cations (mmol/l)` = Sum.of.cations*1000
  )%>% select(-c(
    SO4_mol, charge_diff, Alk_Acid_mol, org_charge, Sum.of.cations, sample_id, mvm_id
    )) %>% rename(
      `TOC (mg/l)` = TOC_mg_l,
      `Org. Charge Density (meq/g of C)` = org_charge_density_meq_g_C,
      `EC (mS/M)` = EC_mS_m,
      `Absorbance 420mm` = Abs_F420_5cm, 
      `ADOM/DOC` = adom_doc,
      `Ionic strength` = Ionic.strength, 
      `Field pH` = pH_
    ), out = "kable", group = "period", group.weights = "weight", summ=c('notNA(x)',
                'reldist::wtd.quantile (x, q=0.50, na.rm = TRUE, weight = wts)',
                'reldist::wtd.quantile (x, q=0.75, na.rm = TRUE, weight = wts) - reldist::wtd.quantile (x, q=0.25, na.rm = TRUE, weight = wts)'), summ.names = c("N", "Median", "IQR")
             ) # %>% kable_styling(font_size = 10)
```


```{r}
#| label: fig-bar-water-chem
#| fig-cap: Bargraphs of water chemistry parameters modelled and observed for the three periods.
#| fig-height: 10
#| fig-width: 8

library(dplyr)
library(ggplot2)
library(matrixStats)
library(tidyr)


data_with_weights %>% mutate(
  `SO4 (mmol/l)` = SO4_mol *1000,
  `Alk Acid (mmol/l)` = Alk_Acid_mol *1000,
  `Organic charge (meq/l)` = org_charge*1000, 
  `Sum of Cations (meq/l)` = Sum.of.cations*1000
  )%>% select(-c(
    SO4_mol, Alk_Acid_mol, org_charge, Sum.of.cations, sample_id
    )) %>% rename(
      `TOC (mg/l)` = TOC_mg_l,
      `Org. Charge Density (meq/g of C)` = org_charge_density_meq_g_C,
      `EC (mS/m)` = EC_mS_m,
      `Absorbance 420mm` = Abs_F420_5cm, 
      `ADOM/DOC` = adom_doc,
      `Ionic strength` = Ionic.strength, 
      `Field pH` = pH_,
      `Charge Difference (%)` = charge_diff
    ) -> data_with_weights_1

variables = c('TOC (mg/l)', 'sVISa', 'Alk Acid (mmol/l)', 'Organic charge (meq/l)', 'Org. Charge Density (meq/g of C)', 'SO4 (mmol/l)', 'EC (mS/m)', 'Absorbance 420mm', 'Field pH',"Sum of Cations (meq/l)", "Al total (µmol/l)", "Si (mmol/l)", "Cl (mmol/l)" , "F (µmol/l)", "Charge Difference (%)")


# Ensure all relevant columns are numeric
data_with_weights_1 <- data_with_weights_1 %>%
  mutate(across(all_of(variables), as.numeric))

# Reshape the data into a long format
long_data <- data_with_weights_1 %>%
  pivot_longer(cols = variables,
               names_to = "variable", values_to = "value") %>% 
                 mutate(variable = fct_relevel(variable, 
                                "TOC (mg/l)", 
                                "sVISa",
                                "Absorbance 420mm", 
                                "Organic charge (meq/l)", 
                                "Org. Charge Density (meq/g of C)",
                                "Charge Difference (%)" ,
                                "Alk Acid (mmol/l)",
                                "SO4 (mmol/l)", 
                                "EC (mS/m)",  
                                "Field pH", 
                                "Sum of Cations (meq/l)", 
                                "Si (mmol/l)", 
                                "Cl (mmol/l)", 
                                "Al total (µmol/l)", 
                                "F (µmol/l)"))
    

# Calculate weighted summary statistics for each variable and period
weighted_summary <- long_data %>%
  group_by(period, variable) %>%
  summarise(
    N = sum(!is.na(value)),
    Median = weightedMedian(value, w = weight, na.rm = TRUE),
    Q25 = weightedQuantile(value, w = weight, probs = 0.75, na.rm = TRUE),
    Q75 = weightedQuantile(value, w = weight, probs = 0.25, na.rm = TRUE)
  )

facet_labels <- c(
  `TOC (mg/l)` = "a) TOC (mg/l)",
  `sVISa` = "b) sVISa",
  `Absorbance 420mm` = "c) Absorbance 420mm",
  `Organic charge (meq/l)` = "d) Organic charge (meq/l)",
  `Org. Charge Density (meq/g of C)` = "e) Org. Charge Density (meq/g of C)",
  `Charge Difference (%)` = "f) Charge Difference (%)",
  `Alk Acid (mmol/l)` = "g) Alk Acid (mmol/l)",
  `SO4 (mmol/l)` = "h) SO4 (mmol/l)",
  `EC (mS/m)` = "i) EC (mS/m)",
  `Field pH` = "j) Field pH",
  `Sum of Cations (meq/l)` = "k) Sum of Cations (meq/l)",
  `Si (mmol/l)` = "l) Si (mmol/l)",
  `Cl (mmol/l)` = "m) Cl (mmol/l)",
  `Al total (µmol/l)` = "n) Al total (µmol/l)",
  `F (µmol/l)` = "o) F (µmol/l)"
)

# Create the plot with facets for each variable
ggplot(weighted_summary, aes(x = period, y = Median, fill = period)) +
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin = Q25, ymax = Q75), width = 0.2) +
  labs(y = "Median Value", x = "Period") +
  theme_minimal() +
  theme(legend.position = "none",
   strip.text = element_text(hjust = 0)) +
  facet_wrap(~ variable, scales = "free_y", ncol = 3, labeller = labeller(variable = facet_labels) ) +
  scale_fill_brewer(palette = "Set2") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


```{r}
#| fig.cap: "Histogram of the number of samples per station for each period. Stations with more than two samples were used in significance testing, the number of these stations are in the title as (number of station/total number of stations)."
#| label: fig-stations-periods
#| out.width: 100%

summary_stats <- data_periods %>% arrange(sampling_date) %>%
  group_by(mvm_id, period) %>%
  summarise(
    median= median(TOC_mg_l, na.rm = TRUE),
    iqr = IQR(TOC_mg_l, na.rm = TRUE),  # Interquartile Range
    n = n()  # Count of observations per group
  ) %>%
  ungroup()

summary_stats_complete <- summary_stats %>%
  complete(mvm_id, period, fill = list(n = 0 ))


library(dplyr)
library(ggplot2)

# Calculate the number of stations with n > 2 for each period
stations_gt_2_per_period <- summary_stats_complete %>%
  filter(n > 2) %>%
  group_by(period) %>%
  summarise(num_stations = n_distinct(mvm_id))

# Create custom facet labels
facet_labels <- stations_gt_2_per_period %>%
  mutate(label = paste0(period, " \n(", num_stations, "/136)")) %>%
  select(period, label) %>%
  deframe()

# Create the plot with custom facet labels
summary_stats_complete %>%
  filter(n > 2) %>%
  ggplot(aes(x = n, fill = period)) +
  geom_histogram(position = "dodge", binwidth = 20) +
  facet_wrap(~ period, ncol = 3, labeller = labeller(period = facet_labels)) +
  xlab("Number of samples per station") +
  ylab("Number of stations") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set2")+
  labs(fill = "Period")
```

## Significant Testing

---

### sVISa

```{r}

#| fig.cap: "Kruskal Wallis with confidence interval of 95% to find number of stations with significant differences bettwen the periods. "
#| label: fig-sig-sVISa
#| out.width: 60%

summary_stats <- data_periods %>% arrange(sampling_date) %>%
  group_by(mvm_id, period) %>%
  summarise(
    median= median(sVISa, na.rm = TRUE),
    iqr = IQR(sVISa, na.rm = TRUE),  # Interquartile Range
    n = n()  # Count of observations per group
  ) %>%
  ungroup()


# Step 3: Reshape the data to have periods as columns
summary_table <- summary_stats %>%
  pivot_wider(
    names_from = period,
    values_from = c(median, iqr, n)
  )

# Step 4: Filter data for Kruskal-Wallis testing
# Ensure each group (mvm_id) has more than one period and non-identical sVISa values across periods
testable_data <- data_periods %>% arrange(sampling_date) %>%
  group_by(mvm_id) %>%
  filter(n_distinct(period) > 1) %>%  # At least two periods
  filter(n_distinct(sVISa[!is.na(sVISa)]) > 2) %>%  # At least two unique sVISa values
  summarise(kruskal_p_value = tryCatch({
    kruskal.test(sVISa ~ period)$p.value  # Run Kruskal-Wallis only if conditions met
  }, error = function(e) {
    message("Error in Kruskal-Wallis test for mvm_id ", unique(mvm_id), ": ", e$message)
    NA
  }))
  # Return NA if test fails

# Step 5: Merge the significance results with the summary table
final_table <- left_join(summary_table, testable_data, by = "mvm_id")

# View the final table with significance results
# kable(final_table)

# Create a summary table that counts the number of mvm_ids with significant and non-significant differences:
summary_significance <- final_table %>%
  mutate(significant = case_when (kruskal_p_value < 0.05 ~ "Significant", kruskal_p_value >= 0.05 ~"Not Significant", 
  TRUE ~ "No Data")) %>% as_tibble() %>%
  dplyr::count(significant)


# You can create a bar plot to visualize the proportion of mvm_id with significant vs. non-significant differences:

ggplot(summary_significance, aes(x = significant, y = n, fill = significant)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = n), vjust = -0.5) +
  labs(title = "",
       x = "Significance", y = "Number of Stations") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set2")
```
```{r}
#| cache-refresh: true
#| label: tbl-sVISa-significance
#| tbl-cap: sVISa significance using Kruskal Wallis to determine significance and then Dunn's test as a post hoc test to find the significant differences.

library(FSA)

# Perform pairwise Dunn's test for each mvm_id
# Ensure period is a factor

data_periods <- data_periods %>%
  mutate(period = as.factor(period))

mvm_ids_sig <- final_table %>% filter((kruskal_p_value < 0.05)) %>% select(mvm_id)
# Perform Dunn's test for each mvm_id
pairwise_results <- data_periods %>%
  arrange(sampling_date) %>%
  filter(mvm_id %in% mvm_ids_sig$mvm_id) %>%
  group_by(mvm_id) %>%
  filter(n_distinct(period) > 1) %>%
  group_modify(~ {
    tryCatch(
      data.frame(
        dunn_test = list(as.data.frame(dunnTest(sVISa ~ period, data = .x, method = "bonferroni")$res))
      ),
      error = function(e) data.frame(dunn_test_summary = list(NULL))  # Handle errors
    )
  }) %>%
  ungroup()


# View the result
# pairwise_results %>% filter(dunn_test.P.adj < 0.05)

summary_dunns <- pairwise_results %>% group_by(dunn_test.Comparison) %>%
  mutate(significant = ifelse(dunn_test.P.adj < 0.05, "Significant", "Not Significant")) %>%
  dplyr::count(significant) %>% ungroup() %>%
  pivot_wider(
    names_from = significant,  # Create columns based on the 'significant' values
    values_from = n,           # Populate these columns with values from 'n'
    values_fill = 0            # Fill missing values with 0
  )

kable(summary_dunns)
```

```{r}
#| fig.cap: sVISa changes between periods. Only stations for which Kruskall-Wallis test found a significant difference between periods are included. In the tile is indicated how many station out of all the stations that had significant results between the periods had data for a comparison during the specified periods.
#| label: fig-bar-sVISa
#| fig-width: 8
#| fig-height: 8

library(forcats)
pairwise_results %>% mutate(significance = case_when(
    dunn_test.P.adj >= 0.05~ "not_sig", 
    dunn_test.P.adj < 0.05 & dunn_test.Z < 0 ~ "sig_increase",
    dunn_test.P.adj < 0.05 & dunn_test.Z > 0 ~ "sig_decrease")) %>%
  complete(mvm_id, dunn_test.Comparison, fill = list(significance = "no data")) %>% left_join(stations %>% select(mvm_id, stationCoordinateY)) %>% 
  mutate(mvm_id = fct_reorder(as.factor(mvm_id), stationCoordinateY)) %>% 
  mutate(dunn_test.Comparison = str_replace(dunn_test.Comparison, " - ", "\n")) %>% 
  mutate(dunn_test.Comparison = fct_relevel(dunn_test.Comparison, "1990-1997\n1998-2012", "1998-2012\n2012-2024", "1990-1997\n2012-2024")) -> pairwise_results


ggplot(pairwise_results, aes(x = as.factor(mvm_id), fill = significance)) +
  geom_bar(position = "fill") +
  facet_wrap(~ dunn_test.Comparison) +
  labs(x = "Station (mvm_id)", y = "Proportion", fill = "Significance") +
  theme_minimal() +
  scale_fill_manual(values = c("sig_increase" = "#D55E00", "sig_decrease" = "#56B4E9", "not_sig" = "#F0E442", "no data" = 'white')) +
  coord_flip() +
  ylab("Dunn's test")+
  xlab("Stations")+
    theme(axis.ticks.x = element_blank(), axis.text.x = element_blank(), axis.text = element_text(size = 4.5))
```

```{r}
#| tab-cap: Information on how many stations had data for each period for sVISa.
#| label: table-significance-sVISa
library(dplyr)

# Calculate the total number of stations for each period
total_stations_per_period <- pairwise_results %>%
  group_by(dunn_test.Comparison) %>%
  summarise(total_stations = n_distinct(mvm_id))

# Calculate the number of stations for each significance category within each period
stations_with_data <- pairwise_results %>%
  group_by(dunn_test.Comparison, significance) %>%
  summarise(num_stations = n_distinct(mvm_id)) %>%
  ungroup()

# Combine the summaries into a single data frame
summary_stations <- stations_with_data %>%
  left_join(total_stations_per_period, by = "dunn_test.Comparison") %>%
  pivot_wider(names_from = significance, values_from = num_stations, values_fill = list(num_stations = 0)) %>%
  rename(
    `Total Stations` = total_stations,
    `Significant Increase` = sig_increase,
    `Significant Decrease` = sig_decrease,
    `Not Significant` = not_sig,
    `No data` = `no data`
  )

# Print the summary data frame
kable(summary_stations)

```

```{r}
#| fig.cap: sVISa of all stations not weighted.
#| fig.subcap:
#|      - "Median"
#|      - "IQR"
#| layout-ncol: 2
#| label: fig-box-sVISa
#| 
ggplot(summary_stats, aes(x = period, y = median, fill = period)) +
  geom_boxplot() +
  # geom_text(aes(
  #   x = period,
  #   y = max(median, na.rm = TRUE) + 0.002,  # Adjust text position
  #   label = paste0("sig n: ", sig_n, "\ninsig n: ", insig_n)
  # ), color = "black", size = 4, position = position_dodge(width = 0.9)) +
  labs(x = "Period", y = "Median sVISa") +
  theme_minimal() +
  theme(legend.position = "none")

ggplot(summary_stats, aes(x = period, y = iqr, fill = period)) +
  geom_boxplot() +
  # geom_text(aes(
  #   x = period,
  #   y = max(median, na.rm = TRUE) + 0.002,  # Adjust text position
  #   label = paste0("sig n: ", sig_n, "\ninsig n: ", insig_n)
  # ), color = "black", size = 4, position = position_dodge(width = 0.9)) +
  labs(x = "Period", y = "IQR sVISa") +
  theme_minimal() +
  theme(legend.position = "none")
```

### TOC

```{r}
#| fig.cap: "Kruskal Wallis with confidence interval of 95% to find number of stations with significant differences bettwen the periods." 
#| label: fig-sig-TOC
#| out.width: 60%

data_periods %>% rename(TOC = TOC_mg_l) -> data_periods

summary_stats <- data_periods %>% arrange(sampling_date) %>%
  group_by(mvm_id, period) %>%
  summarise(
    median= median(TOC, na.rm = TRUE),
    iqr = IQR(TOC, na.rm = TRUE),  # Interquartile Range
    n = n()  # Count of observations per group
  ) %>%
  ungroup()

# Step 3: Reshape the data to have periods as columns
summary_table <- summary_stats %>%
  pivot_wider(
    names_from = period,
    values_from = c(median, iqr, n)
  )

# Step 4: Filter data for Kruskal-Wallis testing
# Ensure each group (mvm_id) has more than one period and non-identical TOC values across periods
testable_data <- data_periods %>% arrange(sampling_date) %>%
  group_by(mvm_id) %>%
  filter(n_distinct(period) > 1) %>%  # At least two periods
  filter(n_distinct(TOC[!is.na(TOC)]) > 2) %>%  # At least two unique TOC values
  summarise(kruskal_p_value = tryCatch({
    kruskal.test(TOC ~ period)$p.value  # Run Kruskal-Wallis only if conditions met
  }, error = function(e) {
    message("Error in Kruskal-Wallis test for mvm_id ", unique(mvm_id), ": ", e$message)
    NA
  }))
  # Return NA if test fails

# Step 5: Merge the significance results with the summary table
final_table <- left_join(summary_table, testable_data, by = "mvm_id")

# View the final table with significance results
# kable(final_table)

# Create a summary table that counts the number of mvm_ids with significant and non-significant differences:
summary_significance <- final_table %>%
  mutate(significant = case_when (kruskal_p_value < 0.05 ~ "Significant", kruskal_p_value >= 0.05 ~"Not Significant", 
  TRUE ~ "No Data")) %>% as_tibble() %>%
  dplyr::count(significant)


# You can create a bar plot to visualize the proportion of mvm_id with significant vs. non-significant differences:

ggplot(summary_significance, aes(x = significant, y = n, fill = significant)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = n), vjust = -0.5) +
  labs(title = "Significance of Differences Across Periods for Each Station",
       x = "Significance", y = "Number of Stations") +
  theme_minimal()
```
```{r}
#| cache-refresh: true
#| label: tbl-TOC-significance
#| tbl-cap: TOC significance using Kruskal Wallis to determine significance and then Dunn's test as a post hoc test to find the significant differences.

library(FSA)

# Perform pairwise Dunn's test for each mvm_id
# Ensure period is a factor

data_periods <- data_periods %>%
  mutate(period = as.factor(period))

mvm_ids_sig <- final_table %>% filter((kruskal_p_value < 0.05)) %>% select(mvm_id)
# Perform Dunn's test for each mvm_id
pairwise_results <- data_periods %>%
  arrange(sampling_date) %>%
  filter(mvm_id %in% mvm_ids_sig$mvm_id) %>%
  group_by(mvm_id) %>%
  filter(n_distinct(period) > 1) %>%
  group_modify(~ {
    tryCatch(
      data.frame(
        dunn_test = list(as.data.frame(dunnTest(TOC ~ period, data = .x, method = "bonferroni")$res))
      ),
      error = function(e) data.frame(dunn_test_summary = list(NULL))  # Handle errors
    )
  }) %>%
  ungroup()


# View the result
# pairwise_results %>% filter(dunn_test.P.adj < 0.05)

summary_dunns <- pairwise_results %>% group_by(dunn_test.Comparison) %>%
  mutate(significant = ifelse(dunn_test.P.adj < 0.05, "Significant", "Not Significant")) %>%
  dplyr::count(significant) %>% ungroup() %>%
  pivot_wider(
    names_from = significant,  # Create columns based on the 'significant' values
    values_from = n,           # Populate these columns with values from 'n'
    values_fill = 0            # Fill missing values with 0
  )

kable(summary_dunns)
```

```{r}
#| fig.cap: TOC changes between periods. Only stations for which Kruskall-Wallis test found a significant difference between periods are included. In the tile is indicated how many station out of all the stations that had significant results between the periods had data for a comparison during the specified periods.
#| label: fig-bar-TOC
#| fig-width: 8
#| fig-height: 8

library(forcats)
pairwise_results %>% mutate(significance = case_when(
    dunn_test.P.adj >= 0.05~ "not_sig", 
    dunn_test.P.adj < 0.05 & dunn_test.Z < 0 ~ "sig_increase",
    dunn_test.P.adj < 0.05 & dunn_test.Z > 0 ~ "sig_decrease")) %>%
  complete(mvm_id, dunn_test.Comparison, fill = list(significance = "no data")) %>% left_join(stations %>% select(mvm_id, stationCoordinateY)) %>% 
  mutate(mvm_id = fct_reorder(as.factor(mvm_id), stationCoordinateY)) %>% 
  mutate(dunn_test.Comparison = str_replace(dunn_test.Comparison, " - ", "\n")) %>% 
  mutate(dunn_test.Comparison = fct_relevel(dunn_test.Comparison, "1990-1997\n1998-2012", "1998-2012\n2012-2024", "1990-1997\n2012-2024")) -> pairwise_results


ggplot(pairwise_results, aes(x = as.factor(mvm_id), fill = significance)) +
  geom_bar(position = "fill") +
  facet_wrap(~ dunn_test.Comparison) +
  labs(x = "Station (mvm_id)", y = "Proportion", fill = "Significance") +
  theme_minimal() +
  scale_fill_manual(values = c("sig_increase" = "#D55E00", "sig_decrease" = "#56B4E9", "not_sig" = "#F0E442", "no data" = 'white')) +
  coord_flip() +
  ylab("Dunn's test")+
  xlab("Stations")+
    theme(axis.ticks.x = element_blank(), axis.text.x = element_blank(), axis.text = element_text(size = 4.5))
```

```{r}
#| tab-cap: Information on how many stations had data for each period for TOC.
#| label: table-significance-TOC
library(dplyr)

# Calculate the total number of stations for each period
total_stations_per_period <- pairwise_results %>%
  group_by(dunn_test.Comparison) %>%
  summarise(total_stations = n_distinct(mvm_id))

# Calculate the number of stations for each significance category within each period
stations_with_data <- pairwise_results %>%
  group_by(dunn_test.Comparison, significance) %>%
  summarise(num_stations = n_distinct(mvm_id)) %>%
  ungroup()

# Combine the summaries into a single data frame
summary_stations <- stations_with_data %>%
  left_join(total_stations_per_period, by = "dunn_test.Comparison") %>%
  pivot_wider(names_from = significance, values_from = num_stations, values_fill = list(num_stations = 0)) %>%
  rename(
    `Total Stations` = total_stations,
    `Significant Increase` = sig_increase,
    `Significant Decrease` = sig_decrease,
    `Not Significant` = not_sig,
    `No data` = `no data`
  )

# Print the summary data frame
kable(summary_stations)

```

```{r}
#| fig.cap: TOC of all stations
#| fig.subcap:
#|      - "Median"
#|      - "IQR"
#| layout-ncol: 2
#| label: fig-box-TOC
#| 
ggplot(summary_stats, aes(x = period, y = median, fill = period)) +
  geom_boxplot() +
  # geom_text(aes(
  #   x = period,
  #   y = max(median, na.rm = TRUE) + 0.002,  # Adjust text position
  #   label = paste0("sig n: ", sig_n, "\ninsig n: ", insig_n)
  # ), color = "black", size = 4, position = position_dodge(width = 0.9)) +
  labs(x = "Period", y = "Median TOC (mg/l)") +
  theme_minimal() +
  theme(legend.position = "none")

ggplot(summary_stats, aes(x = period, y = iqr, fill = period)) +
  geom_boxplot() +
  # geom_text(aes(
  #   x = period,
  #   y = max(median, na.rm = TRUE) + 0.002,  # Adjust text position
  #   label = paste0("sig n: ", sig_n, "\ninsig n: ", insig_n)
  # ), color = "black", size = 4, position = position_dodge(width = 0.9)) +
  labs(x = "Period", y = "IQR TOC (mg/l)") +
  theme_minimal() +
  theme(legend.position = "none")
```

### Organic charge density

```{r}
#| fig.cap: Kruskal Wallis with confidence interval of 95% to find number of stations with significant differences bettwen the periods. 
#| label: fig-sig-org_charge_density
#| out.width: 60%

data_periods <- data_periods %>% mutate(org_charge_density = org_charge_density_meq_g_C)

summary_stats <- data_periods %>% arrange(sampling_date) %>%
  group_by(mvm_id, period) %>%
  summarise(
    median= median(org_charge_density, na.rm = TRUE),
    iqr = IQR(org_charge_density, na.rm = TRUE),  # Interquartile Range
    n = n()  # Count of observations per group
  ) %>%
  ungroup()

# Step 3: Reshape the data to have periods as columns
summary_table <- summary_stats %>%
  pivot_wider(
    names_from = period,
    values_from = c(median, iqr, n)
  )

# Step 4: Filter data for Kruskal-Wallis testing
# Ensure each group (mvm_id) has more than one period and non-identical org_charge_density values across periods
testable_data <- data_periods %>% arrange(sampling_date) %>%
  group_by(mvm_id) %>%
  filter(n_distinct(period) > 1) %>%  # At least two periods
  filter(n_distinct(org_charge_density[!is.na(org_charge_density)]) > 2) %>%  # At least two unique org_charge_density values
  summarise(kruskal_p_value = tryCatch({
    kruskal.test(org_charge_density ~ period)$p.value  # Run Kruskal-Wallis only if conditions met
  }, error = function(e) {
    message("Error in Kruskal-Wallis test for mvm_id ", unique(mvm_id), ": ", e$message)
    NA
  }))
  # Return NA if test fails

# Step 5: Merge the significance results with the summary table
final_table <- left_join(summary_table, testable_data, by = "mvm_id")

# View the final table with significance results
# kable(final_table)

# Create a summary table that counts the number of mvm_ids with significant and non-significant differences:
summary_significance <- final_table %>%
  mutate(significant = case_when (kruskal_p_value < 0.05 ~ "Significant", kruskal_p_value >= 0.05 ~"Not Significant", 
  TRUE ~ "No Data")) %>% as_tibble() %>%
  dplyr::count(significant)


# You can create a bar plot to visualize the proportion of mvm_id with significant vs. non-significant differences:

ggplot(summary_significance, aes(x = significant, y = n, fill = significant)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = n), vjust = -0.5) +
  labs(title = "Significance of Differences Across Periods for Each Station",
       x = "Significance", y = "Number of Stations") +
  theme_minimal()
```
```{r}
#| cache-refresh: true
#| label: tbl-org_charge_density-significance
#| tbl-cap: org_charge_density significance using Kruskal Wallis to determine significance and then Dunn's test as a post hoc test to find the significant differences.

library(FSA)

# Perform pairwise Dunn's test for each mvm_id
# Ensure period is a factor

data_periods <- data_periods %>%
  mutate(period = as.factor(period))

mvm_ids_sig <- final_table %>% filter((kruskal_p_value < 0.05)) %>% select(mvm_id)
# Perform Dunn's test for each mvm_id
pairwise_results <- data_periods %>%
  arrange(sampling_date) %>%
  filter(mvm_id %in% mvm_ids_sig$mvm_id) %>%
  group_by(mvm_id) %>%
  filter(n_distinct(period) > 1) %>%
  group_modify(~ {
    tryCatch(
      data.frame(
        dunn_test = list(as.data.frame(dunnTest(org_charge_density ~ period, data = .x, method = "bonferroni")$res))
      ),
      error = function(e) data.frame(dunn_test_summary = list(NULL))  # Handle errors
    )
  }) %>%
  ungroup()


# View the result
# pairwise_results %>% filter(dunn_test.P.adj < 0.05)

summary_dunns <- pairwise_results %>% group_by(dunn_test.Comparison) %>%
  mutate(significant = ifelse(dunn_test.P.adj < 0.05, "Significant", "Not Significant")) %>%
  dplyr::count(significant) %>% ungroup() %>%
  pivot_wider(
    names_from = significant,  # Create columns based on the 'significant' values
    values_from = n,           # Populate these columns with values from 'n'
    values_fill = 0            # Fill missing values with 0
  )

kable(summary_dunns)
```

```{r}
#| fig.cap: Organic charge density changes between periods. Only stations for which Kruskall-Wallis test found a significant difference between periods are included. In the tile is indicated how many station out of all the stations that had significant results between the periods had data for a comparison during the specified periods. 
#| label: fig-bar-org_density¨
#| fig-width: 8
#| fig-height: 8

library(forcats)
pairwise_results %>% mutate(significance = case_when(
    dunn_test.P.adj >= 0.05~ "not_sig", 
    dunn_test.P.adj < 0.05 & dunn_test.Z < 0 ~ "sig_increase",
    dunn_test.P.adj < 0.05 & dunn_test.Z > 0 ~ "sig_decrease")) %>%
  complete(mvm_id, dunn_test.Comparison, fill = list(significance = "no data")) %>% left_join(stations %>% select(mvm_id, stationCoordinateY)) %>% 
  mutate(mvm_id = fct_reorder(as.factor(mvm_id), stationCoordinateY)) %>% 
  mutate(dunn_test.Comparison = str_replace(dunn_test.Comparison, " - ", "\n")) %>% 
  mutate(dunn_test.Comparison = fct_relevel(dunn_test.Comparison, "1990-1997\n1998-2012", "1998-2012\n2012-2024", "1990-1997\n2012-2024")) -> pairwise_results


ggplot(pairwise_results, aes(x = as.factor(mvm_id), fill = significance)) +
  geom_bar(position = "fill") +
  facet_wrap(~ dunn_test.Comparison) +
  labs(x = "Station (mvm_id)", y = "Proportion", fill = "Significance") +
  theme_minimal() +
  scale_fill_manual(values = c("sig_increase" = "#D55E00", "sig_decrease" = "#56B4E9", "not_sig" = "#F0E442", "no data" = 'white')) +
  coord_flip() +
  ylab("Dunn's test")+
  xlab("Stations")+
    theme(axis.ticks.x = element_blank(), axis.text.x = element_blank(), axis.text = element_text(size = 4.5))
```

```{r}
#| tab-cap: Information on how many stations had data for each period for organic charge density.
#| label: table-significance-org
library(dplyr)

# Calculate the total number of stations for each period
total_stations_per_period <- pairwise_results %>%
  group_by(dunn_test.Comparison) %>%
  summarise(total_stations = n_distinct(mvm_id))

# Calculate the number of stations for each significance category within each period
stations_with_data <- pairwise_results %>%
  group_by(dunn_test.Comparison, significance) %>%
  summarise(num_stations = n_distinct(mvm_id)) %>%
  ungroup()

# Combine the summaries into a single data frame
summary_stations <- stations_with_data %>%
  left_join(total_stations_per_period, by = "dunn_test.Comparison") %>%
  pivot_wider(names_from = significance, values_from = num_stations, values_fill = list(num_stations = 0)) %>%
  rename(
    `Total Stations` = total_stations,
    `Significant Increase` = sig_increase,
    `Significant Decrease` = sig_decrease,
    `Not Significant` = not_sig,
    `No data` = `no data`
  )

# Print the summary data frame
kable(summary_stations)

```

```{r}
#| fig.cap: Organic charge density of all stations
#| fig.subcap:
#|      - "Median"
#|      - "IQR"
#| layout-ncol: 2
#| label: fig-box-org_charge_density
#| 
ggplot(summary_stats, aes(x = period, y = median, fill = period)) +
  geom_boxplot() +
  # geom_text(aes(
  #   x = period,
  #   y = max(median, na.rm = TRUE) + 0.002,  # Adjust text position
  #   label = paste0("sig n: ", sig_n, "\ninsig n: ", insig_n)
  # ), color = "black", size = 4, position = position_dodge(width = 0.9)) +
  labs(x = "Period", y = "Median org_charge_density") +
  theme_minimal() +
  theme(legend.position = "none")

ggplot(summary_stats, aes(x = period, y = iqr, fill = period)) +
  geom_boxplot() +
  # geom_text(aes(
  #   x = period,
  #   y = max(median, na.rm = TRUE) + 0.002,  # Adjust text position
  #   label = paste0("sig n: ", sig_n, "\ninsig n: ", insig_n)
  # ), color = "black", size = 4, position = position_dodge(width = 0.9)) +
  labs(x = "Period", y = "IQR org_charge_density") +
  theme_minimal() +
  theme(legend.position = "none")
```

---



# Spatial Patterns

## Overview

```{r}
#| cache-refresh: false
# merge response and landuse as one dataframe called all
all <- data_1 %>%
 group_by(mvm_id) %>% summarise(org_charge_meq_g_C = median(org_charge_density_meq_g_C), median_toc = median(TOC_mg_l), median_sVISa = median(sVISa, na.rm = TRUE)) %>%
 ungroup() %>% mutate(mvm_id = as_factor(mvm_id))%>% 
 select(mvm_id, org_charge_meq_g_C, median_toc, median_sVISa) %>%
 left_join(catch_char, by = join_by(mvm_id))

all %>% write.csv("../results/r_py/pls_input.csv")
```

---

```{r}
#| echo: false
#| fig-cap: Water chemistry modelled and observed for 136 stations with available data that were sucessfully modelled in this study. The size of the marker is related to the size of the color while the color shows the observed median TOC (left), the observed sVISa (middle), and the modelled organic charge density (right) of the catchment of the station.
#| fig-alt: Map of results
#| label: fig-map-results
#| out-width: 100%
#| cache-refresh: true
knitr::include_graphics("../results/reports/maps/map_results.png")
```

**sVISa**

sVISa is the specific visual absorbance calculated as: 

$$
\text{sVISa} =  \frac{\text{Absorbance filtered 420mm at 5cm depth}}{\text{TOC mg/C}}
$$

It is similar to SUVA, which uses Absorbance at 254mm instead of 420mm. It is used as an indicator of the character of DOC. 

---



## Multivariate Spatial Analysis

I chose to use a OPLS instead of a PLS for relating the results to catchment characteristics. Orthogonal Partial Least Squares (OPLS) enables to separately model the variation correlated (predictive) to the factor of interest and the uncorrelated (orthogonal) variation. While performing similarly to PLS, OPLS facilitates easier interpretation. I used the R package [ropls](https://rdrr.io/bioc/ropls/man/opls.html) to perform the below analysis, its the underlying code of the SIMCA software as used in analysis such as [Ehnvall et al., 2023](https://www.sciencedirect.com/science/article/pii/S0048969723037555).

In the OPLS the explantory variables used are catchment characteristics listed in @tbl-catch_char. 


---


### Organic charge

**OPLS**
```{r}
#| cache-refresh: false
source("../src/sourcecode.R")
library(ropls)
library(plotly)

opls.model <- opls(all %>% select(-c(org_charge_meq_g_C,median_sVISa, mvm_id, stationName)), all$org_charge_meq_g_C, orthoI = 1, predI = 1)
```

```{r}
plot_loading_ggplot <- function(opls_model, response_label = "TOC", vip.threshold = 1.0, text_size = 12, title = "Hella Sverige") {
  library(ggplot2)
  library(dplyr)

  # Extract VIP scores and loadings
  vip_data <- enframe(getVipVn(opls_model), name = "Variable", value = "VIP.score")

  # Extract predictive and orthogonal loadings
  loadings_ortho <- getLoadingMN(opls_model, orthoL = TRUE)
  loadings_pred <- getLoadingMN(opls_model, orthoL = FALSE)

  # Convert the loadings to a data frame
  loading_df <- data.frame(
    Variable = rownames(loadings_pred), 
    Predictive_Loading = loadings_pred[, 1],    # Extract the first column for predictive loading
    Orthogonal_Loading = loadings_ortho[, 1]    # Extract the first column for orthogonal loading
  ) %>% 
    left_join(vip_data, by = "Variable") %>%    # Join with VIP data on variable name
    mutate(color = ifelse(VIP.score < vip.threshold, "black", "blue"))

  # Filter for high VIP score variables (VIP > 1)
  loading_VIP <- loading_df %>% filter(VIP.score > 1)

  # Extract the response variable position
  x_1 <- opls_model@cMN[1, 1]  # Assuming the first coefficient as x
  y_1 <- 0.0                    # y set to 0 for the response variable
  resp <- data.frame(x = x_1, y = 0, name = response_label)
  # Create the ggplot
  plot <- ggplot(loading_df, aes(x = Predictive_Loading, y = Orthogonal_Loading)) +
    geom_hline(yintercept = 0, linetype = "solid", color = "black", size = 1) + # Bold horizontal line
  geom_vline(xintercept = 0, linetype = "solid", color = "black", size = 1) + # Bold vertical line
    geom_point(aes(size = VIP.score, color = color), alpha = 0.7) +
    scale_color_identity() +
    scale_size_continuous(range = c(0.1, 1), name = "VIP Score") +
    ggrepel::geom_text_repel(
  data = loading_VIP,
  aes(label = Variable),
  size = text_size / 3,
  max.overlaps = Inf,        # Ensure all labels are shown
  box.padding = 0.5,         # Padding around the labels
  point.padding = 0.5       # Padding around points
) +
    geom_point( data = resp, aes(x = x, y = y), color = "red", size = 5) +
    annotate(data = resp,"text", x = x_1, y = y_1, label = response_label, color = "red", vjust = +2, size = text_size / 3) +
    scale_size_continuous(range = c(1, 10), name = "VIP Score") +
    labs(x = "Predictive Loading", y = "Orthogonal Loading", title = "") +
    theme_minimal() +
    theme(
      legend.position = "none")+scale_size_continuous(range = c(0.5, 3.5), name = "VIP Score")

  return(plot)
}
```

```{r}
#| fig-cap: >
#|   OPLS loading plot for Organic charge density. Blue variables indicate a VIP score > 1 
#|   while black indicate a VIP < 1. The red is the response variable: organic charge density. 
#|   The x axis is the predictive axis indicating covariation with the response while the 
#|   orthogonal axis is variation not explaining any variation in the response variable.
#| label: fig-loading-charge-density
#| fig-alt: OPLS loading plot for Organic charge density.
#| cache-refresh: false

library(tibble)
source("../src/sourcecode.R")
plot_loading_ggplot(opls_model = opls.model, response_label = "Org. charge density", vip.threshold = 1.0, text_size = 12)

```

**PLS**

Here a PLS was run instead of an OPLS for comparison
```{r}
#| cache-refresh: false
pls.model <- opls(all %>% select(-c(org_charge_meq_g_C, median_sVISa, mvm_id, stationName)), all$org_charge_meq_g_C)
```

### sVISa

```{r}
#| cache-refresh: false
opls.model.sVISa <- opls(all %>% filter(median_sVISa > 0) %>% select(-c(org_charge_meq_g_C, mvm_id, median_toc, stationName, median_sVISa)), all %>% filter(median_sVISa > 0) %>% .$median_sVISa, orthoI = 1, predI = 1)
```

```{r}
#| cache-refresh: false
#| fig-cap: >
#|    OPLS loading plot for sVISa. Blue variables indicate a VIP score > 1 while
#|    black indicate a VIP < 1. The red is the response variable: sVISa. The x 
#|    axis is the predictive axis indicating covariation with the response 
#|    while the orthogonal axis is variation not explaining any variation in 
#|    the response variable.  
#| fig-alt: OPLS loading plot for sVISa.
#| label: fig-loading-sVISa
plot_loading_ggplot(opls.model.sVISa, response_label = "sVISa", vip.threshold = 1.0, text_size = 12)
```


### TOC

**OPLS**
```{r}
# TOC
#| cache-refresh: false
#| fig-cap: OPLS loading plot for organic carbon concentrations. Blue variables indicate a VIP score > 1 while black indicate a VIP < 1. The red is the response variable: organic charge density. The x axis is the predictive axis indicating covariation with the response while the orthogonal axis is variation not explaining any variation in the response variable.  
#| fig-alt: OPLS loading plot for toc.
#| label: fig-loading-toc
opls.model.TOC <- opls(all %>% select(-c(org_charge_meq_g_C,median_sVISa, mvm_id, median_toc, stationName)), all$median_toc, orthoI = 1, predI = 1)
```

```{r}
#| cache-refresh: false
plot_loading_ggplot(opls.model.TOC, response_label = "TOC", vip.threshold = 1.0, text_size = 12)
```

**PLS**


```{r}
#| cache-refresh: false
pls.model <- opls(all %>% select(-c(org_charge_meq_g_C,median_toc,median_sVISa, mvm_id, stationName)), all$median_toc)
```

### Comparison

```{r VIP table}
#| cache-refresh: false
VIP_all <- enframe(getVipVn(opls.model), name = "Variable", value = "org.charge") %>%  left_join(enframe(getVipVn(opls.model.TOC), name = "Variable", value = "TOC")) %>% left_join(enframe(getVipVn(opls.model.sVISa), name = "Variable", value = "sVISa")) 

loading_oc <- getLoadingMN(opls.model)[,1]         # Values of the vector become the 'Value' column
loading_toc <- getLoadingMN(opls.model.TOC)[,1] 
loading_sVISa <- getLoadingMN(opls.model.sVISa)[,1] 


# Process each column with its corresponding loading vector
sorted_data <- list(
  Charge_Density = process_column(VIP_all$`org.charge`, loading_oc),
  TOC = process_column(VIP_all$TOC, loading_toc),
  sVISa = process_column(VIP_all$`sVISa`, loading_sVISa)
)

# Find maximum number of rows across all processed data
max_rows <- max(sapply(sorted_data, nrow))

# Pad shorter columns with NA
padded_data <- lapply(sorted_data, function(df) {
  if (nrow(df) < max_rows) {
    padding <- max_rows - nrow(df)
    df <- rbind(df, data.frame(Variable = rep(NA, padding), Value = rep(NA, padding)))
  }
  df
})

# Combine results into a single data frame
sorted_df <- data.frame(
  Org_Charge_Density = padded_data$Charge_Density$Variable,
  Org_Charge_Density_VIP = padded_data$Charge_Density$Value,
  TOC= padded_data$TOC$Variable,
  TOC_VIP = padded_data$TOC$Value,
  sVISa = padded_data$sVISa$Variable,
  sVISa_VIP = padded_data$sVISa$Value
)


new_rows <- data.frame(
  Org_Charge_Density = c("R2", "Q2", "samples", "variables"),
  Org_Charge_Density_VIP = r2_q2(opls.model), # Example values
  TOC = c("R2", "Q2", "samples", "variables"),
  TOC_VIP = r2_q2(opls.model.TOC), # Example values
  sVISa = c("R2", "Q2", "samples", "variables"),
  sVISa_VIP = r2_q2(opls.model.sVISa)
)

final_df <- rbind(new_rows, sorted_df)

# View the sorted data frame

options(knitr.kable.NA = "")
final_df %>%
  kable(.,booktabs = TRUE,   col.names = c("Variable", "VIP", "Variable", "VIP", "Variable", "VIP"))  # %>%
  # kable_styling(latex_options = c("striped", "hold_position", "scale_down"), font_size = 7) %>% # Clean output table
  # add_header_above(c("Organic Charge Density" = 2, "TOC" = 2, "sVISa" = 2)) 

```


---

<!-- 
## Spatial-temporal 

Visualizing how the explantory power changes for the three periods: 1990-1997, 1998-2012, 2013-2024.  

```{r split data}
#| cache-refresh: false
all <- data %>% filter(abs(charge_diff) < 0.5) %>% mutate(sVISa = Abs_F420_5cm/(TOC_mol*12.01))%>% 
filter(year < 2008)%>% 
 group_by(mvm_id) %>% summarise(org_charge_eq_mg_C = median(org_charge_eq_mg_C), median_toc = median(TOC_mol), median_sVISa = median(sVISa, na.rm = TRUE)) %>%
 ungroup() %>% mutate(mvm_id = as_factor(mvm_id))%>% 
 select(mvm_id, org_charge_eq_mg_C, median_toc, median_sVISa) %>%
 left_join(catch_char, by = join_by(mvm_id))


```

---

### Organic Charge Density

```{r}
#| eval: false
#| cache-refresh: false
p1.cd <- opls(all %>% select(-c(org_charge_eq_mg_C,median_sVISa, mvm_id, stationName)), all$org_charge_eq_mg_C, orthoI = 1, predI = 1)
```

### TOC

### Charge Density

--- -->